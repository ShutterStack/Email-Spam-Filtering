{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNSwMg6Is9GDOLmBmFDLuYS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "df76d2cd5b924b68921454900a0c9009": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5d617ce208574a4db3033c0593311233",
              "IPY_MODEL_6be3789ef7bc41f1a769524181df5e54",
              "IPY_MODEL_4a5cd33049434a7ea8f359fd5a4ef6c3"
            ],
            "layout": "IPY_MODEL_d9815005f22143639fd0db9181a3ae7e"
          }
        },
        "5d617ce208574a4db3033c0593311233": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f5485a0621ac42e2b88de6485495c974",
            "placeholder": "​",
            "style": "IPY_MODEL_dc2be20e70eb4ccb8e6e1e6ce32c36c5",
            "value": "vocab.json: 100%"
          }
        },
        "6be3789ef7bc41f1a769524181df5e54": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ac5842efd3914e1788ea465fb11ffa6a",
            "max": 898823,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_debd40b6f0c9497f9eba173465712d06",
            "value": 898823
          }
        },
        "4a5cd33049434a7ea8f359fd5a4ef6c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_58e78fee6e7d494fbdde7ce251e9bd29",
            "placeholder": "​",
            "style": "IPY_MODEL_7b0c77fa88394a8ea95e71316c73c1b4",
            "value": " 899k/899k [00:00&lt;00:00, 11.2MB/s]"
          }
        },
        "d9815005f22143639fd0db9181a3ae7e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f5485a0621ac42e2b88de6485495c974": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dc2be20e70eb4ccb8e6e1e6ce32c36c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ac5842efd3914e1788ea465fb11ffa6a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "debd40b6f0c9497f9eba173465712d06": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "58e78fee6e7d494fbdde7ce251e9bd29": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7b0c77fa88394a8ea95e71316c73c1b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1bc4b41c57bc4e498f496e5a3254ef9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a1aca92a38df4e5485d8a5b24347f1a3",
              "IPY_MODEL_a516a22a44d4410b81348c36a6a5d131",
              "IPY_MODEL_34dde135dd1d4853a750c6da29f0acbe"
            ],
            "layout": "IPY_MODEL_c1e5d4984f874bc2a18c195b645c955a"
          }
        },
        "a1aca92a38df4e5485d8a5b24347f1a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7270401a2dd14ea3b1cd64081befb22b",
            "placeholder": "​",
            "style": "IPY_MODEL_ceeb745904424c4389eb2be6599317aa",
            "value": "merges.txt: 100%"
          }
        },
        "a516a22a44d4410b81348c36a6a5d131": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_55deafed6b404773922a2c5c30b8435c",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_51da76c421cc4b88b32b3277f0be6011",
            "value": 456318
          }
        },
        "34dde135dd1d4853a750c6da29f0acbe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9aa4b83d69c24ef89065068d9e5ec749",
            "placeholder": "​",
            "style": "IPY_MODEL_32f98ae0a21a4ee8a44dae71a9dddb80",
            "value": " 456k/456k [00:00&lt;00:00, 18.4MB/s]"
          }
        },
        "c1e5d4984f874bc2a18c195b645c955a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7270401a2dd14ea3b1cd64081befb22b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ceeb745904424c4389eb2be6599317aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "55deafed6b404773922a2c5c30b8435c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "51da76c421cc4b88b32b3277f0be6011": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9aa4b83d69c24ef89065068d9e5ec749": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "32f98ae0a21a4ee8a44dae71a9dddb80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d346151e1cca48b2a324d6bb33e7166e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_49e1d2986c1c4910b2488661698e8412",
              "IPY_MODEL_496e3f4fec714f93a06d2b2b14ac1d45",
              "IPY_MODEL_37e2a3c0de6e4e83a1d2a55c36c3ce51"
            ],
            "layout": "IPY_MODEL_ae28aed609404ce99591df1774fe9443"
          }
        },
        "49e1d2986c1c4910b2488661698e8412": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_33ce89cb7e0b4f05b2cd02979feb828a",
            "placeholder": "​",
            "style": "IPY_MODEL_b5a3278a9c3a461782bc3d15ad79639d",
            "value": "tokenizer.json: 100%"
          }
        },
        "496e3f4fec714f93a06d2b2b14ac1d45": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_21b5901ad0534c289dc26fde993fc1b3",
            "max": 1355863,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0b9dccb5668e4a0bb77a71b98fd7f12e",
            "value": 1355863
          }
        },
        "37e2a3c0de6e4e83a1d2a55c36c3ce51": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_655defbdf1304708a585b518e98b7864",
            "placeholder": "​",
            "style": "IPY_MODEL_0872be268c404c9a8377dc9e3991862d",
            "value": " 1.36M/1.36M [00:00&lt;00:00, 30.6MB/s]"
          }
        },
        "ae28aed609404ce99591df1774fe9443": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "33ce89cb7e0b4f05b2cd02979feb828a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b5a3278a9c3a461782bc3d15ad79639d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "21b5901ad0534c289dc26fde993fc1b3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0b9dccb5668e4a0bb77a71b98fd7f12e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "655defbdf1304708a585b518e98b7864": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0872be268c404c9a8377dc9e3991862d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e12d1a79464d4a76a9f4bb8ce419e1b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e03282f483044ecba28ae260339e8627",
              "IPY_MODEL_bdd6aea78c294581af7b82bf556b8e2f",
              "IPY_MODEL_7038c2e2f17b4fc9b34e10e87b41c805"
            ],
            "layout": "IPY_MODEL_f10fe032c7ec496fb5836402238167f7"
          }
        },
        "e03282f483044ecba28ae260339e8627": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5e1f1c4acb8b423a8edda21f1db3bbc6",
            "placeholder": "​",
            "style": "IPY_MODEL_0ced5099893c431e98c4034612eced5e",
            "value": "config.json: 100%"
          }
        },
        "bdd6aea78c294581af7b82bf556b8e2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f8e7c4d358ec462281a16f752e55afd4",
            "max": 481,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_17c7e86a7bc04982ab04b307f5161bad",
            "value": 481
          }
        },
        "7038c2e2f17b4fc9b34e10e87b41c805": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0c0ad8a2035a4a9ea3653e42e86de97a",
            "placeholder": "​",
            "style": "IPY_MODEL_679f7e1279e94edea4dcfb73a27a41b3",
            "value": " 481/481 [00:00&lt;00:00, 8.24kB/s]"
          }
        },
        "f10fe032c7ec496fb5836402238167f7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5e1f1c4acb8b423a8edda21f1db3bbc6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0ced5099893c431e98c4034612eced5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f8e7c4d358ec462281a16f752e55afd4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "17c7e86a7bc04982ab04b307f5161bad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0c0ad8a2035a4a9ea3653e42e86de97a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "679f7e1279e94edea4dcfb73a27a41b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d8bb9539e4c24ec4a02dbd57f522d56d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fb20d24c08e44045844d19fe901be94f",
              "IPY_MODEL_129da34db2214b5e9f5cb81d1967915e",
              "IPY_MODEL_882da5b350b54efabcac3f5777f2cde4"
            ],
            "layout": "IPY_MODEL_46a2aa8fc016465e84c4b1688cc1e4db"
          }
        },
        "fb20d24c08e44045844d19fe901be94f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7b8337699acd4183b3d4917521304524",
            "placeholder": "​",
            "style": "IPY_MODEL_470c23ee92f44caab7482de42f73881d",
            "value": "model.safetensors: 100%"
          }
        },
        "129da34db2214b5e9f5cb81d1967915e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_16e1d102c28c418e97930b07291cde7e",
            "max": 498818054,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_30681bda7f76415e857fb08bd9d94427",
            "value": 498818054
          }
        },
        "882da5b350b54efabcac3f5777f2cde4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1c9ae6c0a09b4ebda893f605b1c0fbdc",
            "placeholder": "​",
            "style": "IPY_MODEL_05be009cc89c4283a26f14834fbd4821",
            "value": " 499M/499M [00:05&lt;00:00, 99.5MB/s]"
          }
        },
        "46a2aa8fc016465e84c4b1688cc1e4db": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7b8337699acd4183b3d4917521304524": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "470c23ee92f44caab7482de42f73881d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "16e1d102c28c418e97930b07291cde7e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "30681bda7f76415e857fb08bd9d94427": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1c9ae6c0a09b4ebda893f605b1c0fbdc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "05be009cc89c4283a26f14834fbd4821": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShutterStack/Email-Spam-Filtering/blob/main/Email_Spam_Filterning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JX0e2k63y4Y6",
        "outputId": "66385fbe-d47b-4323-a081-6a58aa5f25b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: chardet in /usr/local/lib/python3.10/dist-packages (5.2.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install chardet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import transformers\n",
        "import random\n",
        "import chardet\n",
        "import warnings\n",
        "warnings.simplefilter('ignore')\n",
        "scaler = torch.cuda.amp.GradScaler()\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eQSdXPA0zEJd",
        "outputId": "2780f3fc-194b-4b81-ae33-90357189d02b"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def random_seed(SEED):\n",
        "\n",
        "    random.seed(SEED)\n",
        "    os.environ['PYTHONHASHSEED'] = str(SEED)\n",
        "    np.random.seed(SEED)\n",
        "    torch.manual_seed(SEED)\n",
        "    torch.cuda.manual_seed(SEED)\n",
        "    torch.cuda.manual_seed_all(SEED)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "\n",
        "SEED = 508\n",
        "random_seed(SEED)"
      ],
      "metadata": {
        "id": "_IfrMhF3zZs-"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data=pd.read_csv('spam.csv', encoding='ISO-8859-1')\n",
        "data=data[['v2','v1']]\n",
        "data.columns=['text','targets']\n",
        "display(data)\n",
        "class_names=sorted(data['targets'].unique().tolist())\n",
        "print(class_names)\n",
        "N=list(range(len(class_names)))\n",
        "normal_mapping=dict(zip(class_names,N))\n",
        "reverse_mapping=dict(zip(N,class_names))\n",
        "data['targets']=data['targets'].map(normal_mapping)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 441
        },
        "id": "zsZxE58V0SSX",
        "outputId": "f26df2be-a611-416f-f71b-11ac483fe068"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                                   text targets\n",
              "0     Go until jurong point, crazy.. Available only ...     ham\n",
              "1                         Ok lar... Joking wif u oni...     ham\n",
              "2     Free entry in 2 a wkly comp to win FA Cup fina...    spam\n",
              "3     U dun say so early hor... U c already then say...     ham\n",
              "4     Nah I don't think he goes to usf, he lives aro...     ham\n",
              "...                                                 ...     ...\n",
              "5567  This is the 2nd time we have tried 2 contact u...    spam\n",
              "5568              Will Ì_ b going to esplanade fr home?     ham\n",
              "5569  Pity, * was in mood for that. So...any other s...     ham\n",
              "5570  The guy did some bitching but I acted like i'd...     ham\n",
              "5571                         Rofl. Its true to its name     ham\n",
              "\n",
              "[5572 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-96488eaa-2eba-4041-936d-1b32ca572cfd\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>targets</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "      <td>ham</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "      <td>ham</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "      <td>spam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "      <td>ham</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "      <td>ham</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5567</th>\n",
              "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
              "      <td>spam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5568</th>\n",
              "      <td>Will Ì_ b going to esplanade fr home?</td>\n",
              "      <td>ham</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5569</th>\n",
              "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
              "      <td>ham</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5570</th>\n",
              "      <td>The guy did some bitching but I acted like i'd...</td>\n",
              "      <td>ham</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5571</th>\n",
              "      <td>Rofl. Its true to its name</td>\n",
              "      <td>ham</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5572 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-96488eaa-2eba-4041-936d-1b32ca572cfd')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-96488eaa-2eba-4041-936d-1b32ca572cfd button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-96488eaa-2eba-4041-936d-1b32ca572cfd');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-b3edd4ae-4527-4c4f-b604-8aeaa199f707\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b3edd4ae-4527-4c4f-b604-8aeaa199f707')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-b3edd4ae-4527-4c4f-b604-8aeaa199f707 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_a006b5e5-f6ba-43bb-ac19-3404fe460ac3\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('data')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_a006b5e5-f6ba-43bb-ac19-3404fe460ac3 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('data');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['ham', 'spam']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(data))\n",
        "data=data.sample(frac=1).reset_index(drop=True)[0:1000]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uDYtOW1Y0Uio",
        "outputId": "0f8428aa-5103-45ea-b24c-1a8d3275f6b2"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5572\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train, test = train_test_split(data, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "jdEmTVTv0ajq"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = transformers.RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
        "#tokenizer = transformers.BertTokenizer.from_pretrained(\"../input/bert-base-uncased\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145,
          "referenced_widgets": [
            "df76d2cd5b924b68921454900a0c9009",
            "5d617ce208574a4db3033c0593311233",
            "6be3789ef7bc41f1a769524181df5e54",
            "4a5cd33049434a7ea8f359fd5a4ef6c3",
            "d9815005f22143639fd0db9181a3ae7e",
            "f5485a0621ac42e2b88de6485495c974",
            "dc2be20e70eb4ccb8e6e1e6ce32c36c5",
            "ac5842efd3914e1788ea465fb11ffa6a",
            "debd40b6f0c9497f9eba173465712d06",
            "58e78fee6e7d494fbdde7ce251e9bd29",
            "7b0c77fa88394a8ea95e71316c73c1b4",
            "1bc4b41c57bc4e498f496e5a3254ef9f",
            "a1aca92a38df4e5485d8a5b24347f1a3",
            "a516a22a44d4410b81348c36a6a5d131",
            "34dde135dd1d4853a750c6da29f0acbe",
            "c1e5d4984f874bc2a18c195b645c955a",
            "7270401a2dd14ea3b1cd64081befb22b",
            "ceeb745904424c4389eb2be6599317aa",
            "55deafed6b404773922a2c5c30b8435c",
            "51da76c421cc4b88b32b3277f0be6011",
            "9aa4b83d69c24ef89065068d9e5ec749",
            "32f98ae0a21a4ee8a44dae71a9dddb80",
            "d346151e1cca48b2a324d6bb33e7166e",
            "49e1d2986c1c4910b2488661698e8412",
            "496e3f4fec714f93a06d2b2b14ac1d45",
            "37e2a3c0de6e4e83a1d2a55c36c3ce51",
            "ae28aed609404ce99591df1774fe9443",
            "33ce89cb7e0b4f05b2cd02979feb828a",
            "b5a3278a9c3a461782bc3d15ad79639d",
            "21b5901ad0534c289dc26fde993fc1b3",
            "0b9dccb5668e4a0bb77a71b98fd7f12e",
            "655defbdf1304708a585b518e98b7864",
            "0872be268c404c9a8377dc9e3991862d",
            "e12d1a79464d4a76a9f4bb8ce419e1b2",
            "e03282f483044ecba28ae260339e8627",
            "bdd6aea78c294581af7b82bf556b8e2f",
            "7038c2e2f17b4fc9b34e10e87b41c805",
            "f10fe032c7ec496fb5836402238167f7",
            "5e1f1c4acb8b423a8edda21f1db3bbc6",
            "0ced5099893c431e98c4034612eced5e",
            "f8e7c4d358ec462281a16f752e55afd4",
            "17c7e86a7bc04982ab04b307f5161bad",
            "0c0ad8a2035a4a9ea3653e42e86de97a",
            "679f7e1279e94edea4dcfb73a27a41b3"
          ]
        },
        "id": "nS2zlSGZ0c0p",
        "outputId": "fef21295-f358-45f6-cc02-8117eccfe76d"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "df76d2cd5b924b68921454900a0c9009"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1bc4b41c57bc4e498f496e5a3254ef9f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d346151e1cca48b2a324d6bb33e7166e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/481 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e12d1a79464d4a76a9f4bb8ce419e1b2"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_s = train['text'].iloc[0]\n",
        "result1 = tokenizer.encode_plus(test_s)\n",
        "tokenizer.decode(result1[\"input_ids\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "ZbnKts4Q0e6h",
        "outputId": "e8a2074f-3350-405c-ec72-3ad99f84bf89"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<s>Understand. his loss is my gain :) so do you work? School?</s>'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(test_s.split(\" \"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f557_yEz0hM5",
        "outputId": "97b01a1a-0d8e-4c89-81fd-318d5ec5f8c7"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result2 = tokenizer.encode_plus(\n",
        "    test_s,\n",
        "    add_special_tokens = True,\n",
        "    max_length = 8,\n",
        "    pad_to_max_length = True,\n",
        "    truncation = True\n",
        ")"
      ],
      "metadata": {
        "id": "-ZyhN-R10i0w"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.decode(result2[\"input_ids\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "eSliTz0Z0kk4",
        "outputId": "cbd9bd53-0320-4c29-90cd-a7253b46b983"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<s>Understand. his loss is</s>'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_sens = 8\n",
        "train = train.sort_values('targets').reset_index(drop=True)\n",
        "train[\"kfold\"] = train.index % 5\n",
        "p_train = train[train[\"kfold\"]!=0].reset_index(drop=True)\n",
        "p_valid = train[train[\"kfold\"]==0].reset_index(drop=True)\n",
        "p_test=test.reset_index(drop=True)"
      ],
      "metadata": {
        "id": "v98DMYk-0mnW"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BERTDataSet(Dataset):\n",
        "\n",
        "    def __init__(self,sentences,targets):\n",
        "        self.sentences = sentences\n",
        "        self.targets = targets\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.sentences)\n",
        "\n",
        "    def __getitem__(self,idx):\n",
        "        sentence = self.sentences[idx]\n",
        "        bert_sens = tokenizer.encode_plus(\n",
        "                                sentence,\n",
        "                                add_special_tokens = True,\n",
        "                                max_length = max_sens,\n",
        "                                pad_to_max_length = True,\n",
        "                                return_attention_mask = True)\n",
        "\n",
        "        ids = torch.tensor(bert_sens['input_ids'], dtype=torch.long)\n",
        "        mask = torch.tensor(bert_sens['attention_mask'], dtype=torch.long)\n",
        "\n",
        "        target = torch.tensor(self.targets[idx],dtype=torch.float)\n",
        "\n",
        "        return {\n",
        "                'ids': ids,\n",
        "                'mask': mask,\n",
        "                'targets': target\n",
        "            }"
      ],
      "metadata": {
        "id": "6Vct0ZM80oue"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = BERTDataSet(p_train[\"text\"],p_train['targets'])\n",
        "valid_dataset = BERTDataSet(p_valid[\"text\"],p_valid['targets'])\n",
        "test_dataset = BERTDataSet(p_test[\"text\"],p_test['targets'])\n",
        "\n",
        "train_batch = 16\n",
        "valid_batch = 32\n",
        "test_batch = 32\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset,batch_size=train_batch,shuffle = True,num_workers=8,pin_memory=True)\n",
        "valid_dataloader = DataLoader(valid_dataset,batch_size=valid_batch,shuffle = False,num_workers=8,pin_memory=True)\n",
        "test_dataloader = DataLoader(test_dataset,batch_size=test_batch,shuffle = False,num_workers=8,pin_memory=True)"
      ],
      "metadata": {
        "id": "IHqlL0hP0sIH"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = transformers.RobertaForSequenceClassification.from_pretrained(\"roberta-base\", num_labels=1)\n",
        "#model = transformers.BertForSequenceClassification.from_pretrained(\"../input/bert-base-uncased\",num_labels=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104,
          "referenced_widgets": [
            "d8bb9539e4c24ec4a02dbd57f522d56d",
            "fb20d24c08e44045844d19fe901be94f",
            "129da34db2214b5e9f5cb81d1967915e",
            "882da5b350b54efabcac3f5777f2cde4",
            "46a2aa8fc016465e84c4b1688cc1e4db",
            "7b8337699acd4183b3d4917521304524",
            "470c23ee92f44caab7482de42f73881d",
            "16e1d102c28c418e97930b07291cde7e",
            "30681bda7f76415e857fb08bd9d94427",
            "1c9ae6c0a09b4ebda893f605b1c0fbdc",
            "05be009cc89c4283a26f14834fbd4821"
          ]
        },
        "id": "_VSIvxex0ut9",
        "outputId": "f6f4bcde-536d-4974-e42c-131393a40a53"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/499M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d8bb9539e4c24ec4a02dbd57f522d56d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.to(device)\n",
        "model.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SK1Vd-X40wy3",
        "outputId": "2404387d-9259-4177-e2d7-84b155f21e36"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RobertaForSequenceClassification(\n",
              "  (roberta): RobertaModel(\n",
              "    (embeddings): RobertaEmbeddings(\n",
              "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
              "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
              "      (token_type_embeddings): Embedding(1, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): RobertaEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (classifier): RobertaClassificationHead(\n",
              "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "    (out_proj): Linear(in_features=768, out_features=1, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for a in train_dataloader:\n",
        "    ids = a[\"ids\"].to(device)\n",
        "    mask = a[\"mask\"].to(device)\n",
        "    output = model(ids,mask)\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L_B3mysk00uy",
        "outputId": "74315419-a595-485e-df18-fd722b1a990c"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output = output[\"logits\"].squeeze(-1).shape"
      ],
      "metadata": {
        "id": "k_iiKD8z035_"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AdamW\n",
        "LR=2e-5\n",
        "optimizer = AdamW(model.parameters(), LR,betas=(0.9, 0.999), weight_decay=1e-2)"
      ],
      "metadata": {
        "id": "A1-mwT5D06Cx"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "epochs = 20\n",
        "#if debug:\n",
        "#    epochs = 1\n",
        "train_steps = int(len(p_train)/train_batch*epochs)\n",
        "print(train_steps)\n",
        "num_steps = int(train_steps*0.1)\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_steps, train_steps)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "od5yqB9F07xz",
        "outputId": "2c8264e7-6b0b-4a9e-f8b1-5ea3e5379356"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "800\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def loss_fn(output,target):\n",
        "    return torch.sqrt(nn.MSELoss()(output,target))"
      ],
      "metadata": {
        "id": "pOv8d-T7096K"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def training(\n",
        "    train_dataloader,\n",
        "    model,\n",
        "    optimizer,\n",
        "    scheduler\n",
        "):\n",
        "\n",
        "    model.train()\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "    allpreds = []\n",
        "    alltargets = []\n",
        "\n",
        "    for a in train_dataloader:\n",
        "\n",
        "        losses = []\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        with torch.cuda.amp.autocast():\n",
        "\n",
        "            ids = a[\"ids\"].to(device,non_blocking=True)\n",
        "            mask = a[\"mask\"].to(device,non_blocking=True)\n",
        "\n",
        "            output = model(ids,mask)\n",
        "            output = output[\"logits\"].squeeze(-1)\n",
        "            target = a[\"targets\"].to(device,non_blocking=True)\n",
        "            loss = loss_fn(output,target)\n",
        "\n",
        "            losses.append(loss.item())\n",
        "            allpreds.append(output.detach().cpu().numpy())\n",
        "            alltargets.append(target.detach().squeeze(-1).cpu().numpy())\n",
        "\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "\n",
        "        del loss\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "    allpreds = np.concatenate(allpreds)\n",
        "    alltargets = np.concatenate(alltargets)\n",
        "    losses = np.mean(losses)\n",
        "    train_rme_loss = np.sqrt(mean_squared_error(alltargets,allpreds))\n",
        "\n",
        "    return losses,train_rme_loss"
      ],
      "metadata": {
        "id": "aO_b-RX91A1b"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def validating(valid_dataloader,model):\n",
        "\n",
        "    model.eval()\n",
        "    allpreds = []\n",
        "    alltargets = []\n",
        "\n",
        "    for a in valid_dataloader:\n",
        "        losses = []\n",
        "        with torch.no_grad():\n",
        "\n",
        "            ids = a[\"ids\"].to(device)\n",
        "            mask = a[\"mask\"].to(device)\n",
        "\n",
        "            output = model(ids,mask)\n",
        "            output = output[\"logits\"].squeeze(-1)\n",
        "            target = a[\"targets\"].to(device)\n",
        "            loss = loss_fn(output,target)\n",
        "            losses.append(loss.item())\n",
        "            allpreds.append(output.detach().cpu().numpy())\n",
        "            alltargets.append(target.detach().squeeze(-1).cpu().numpy())\n",
        "\n",
        "            del loss\n",
        "\n",
        "    allpreds = np.concatenate(allpreds)\n",
        "    alltargets = np.concatenate(alltargets)\n",
        "    losses = np.mean(losses)\n",
        "    valid_rme_loss = np.sqrt(mean_squared_error(alltargets,allpreds))\n",
        "\n",
        "    return allpreds,losses,valid_rme_loss\n"
      ],
      "metadata": {
        "id": "kTV_5kr91Dsv"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainlosses = []\n",
        "vallosses = []\n",
        "bestscore = None\n",
        "trainscores = []\n",
        "validscores = []\n",
        "\n",
        "for epoch in tqdm(range(epochs)):\n",
        "\n",
        "    print(\"---------------\" + str(epoch) + \"start-------------\")\n",
        "\n",
        "    trainloss,trainscore = training(train_dataloader,model,optimizer,scheduler)\n",
        "    trainlosses.append(trainloss)\n",
        "    trainscores.append(trainscore)\n",
        "\n",
        "    print(\"trainscore is \" + str(trainscore))\n",
        "\n",
        "    preds,validloss,valscore=validating(valid_dataloader,model)\n",
        "    vallosses.append(validloss)\n",
        "    validscores.append(valscore)\n",
        "\n",
        "    print(\"valscore is \" + str(valscore))\n",
        "\n",
        "    if bestscore is None:\n",
        "        bestscore = valscore\n",
        "\n",
        "        print(\"Save first model\")\n",
        "\n",
        "        state = {\n",
        "                        'state_dict': model.state_dict(),\n",
        "                        'optimizer_dict': optimizer.state_dict(),\n",
        "                        \"bestscore\":bestscore\n",
        "                    }\n",
        "\n",
        "        torch.save(state, \"model0.pth\")\n",
        "\n",
        "    elif bestscore > valscore:\n",
        "\n",
        "        bestscore = valscore\n",
        "        print(\"found better point\")\n",
        "        state = {\n",
        "                        'state_dict': model.state_dict(),\n",
        "                        'optimizer_dict': optimizer.state_dict(),\n",
        "                        \"bestscore\":bestscore\n",
        "                    }\n",
        "\n",
        "        torch.save(state, \"model0.pth\")\n",
        "\n",
        "    else:\n",
        "        pass"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-HSgKtTo1JPw",
        "outputId": "17f55655-2aae-4a1e-fab6-1a2701e9c1cc"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/20 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------0start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.3605189\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 0.33684075\n",
            "Save first model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  5%|▌         | 1/20 [01:20<25:34, 80.74s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------1start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.32568768\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 0.24630383\n",
            "found better point\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|█         | 2/20 [02:30<22:21, 74.54s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------2start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.25749606\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 0.20151915\n",
            "found better point\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 15%|█▌        | 3/20 [03:40<20:31, 72.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------3start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.16563246\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 0.18544233\n",
            "found better point\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 4/20 [04:51<19:07, 71.74s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------4start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.14701064\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            " 25%|██▌       | 5/20 [05:55<17:11, 68.77s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 0.2140503\n",
            "---------------5start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.1273121\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            " 30%|███       | 6/20 [06:58<15:38, 67.00s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 0.21339673\n",
            "---------------6start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.115214825\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            " 35%|███▌      | 7/20 [08:02<14:16, 65.85s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 0.20125672\n",
            "---------------7start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.11537866\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            " 40%|████      | 8/20 [09:08<13:11, 65.95s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 0.22956757\n",
            "---------------8start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.08463663\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            " 45%|████▌     | 9/20 [10:13<12:01, 65.59s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 0.23170176\n",
            "---------------9start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.088337235\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            " 50%|█████     | 10/20 [11:16<10:49, 65.00s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 0.19480391\n",
            "---------------10start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.0852766\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            " 55%|█████▌    | 11/20 [12:20<09:41, 64.57s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 0.18890224\n",
            "---------------11start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.077626176\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            " 60%|██████    | 12/20 [13:24<08:35, 64.41s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 0.18911952\n",
            "---------------12start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.07819122\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            " 65%|██████▌   | 13/20 [14:28<07:29, 64.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 0.18657668\n",
            "---------------13start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.05742587\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            " 70%|███████   | 14/20 [15:33<06:27, 64.53s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 0.1955503\n",
            "---------------14start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.056267783\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            " 75%|███████▌  | 15/20 [16:37<05:21, 64.33s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 0.1934499\n",
            "---------------15start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.053878773\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 0.18531847\n",
            "found better point\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 16/20 [17:50<04:27, 66.94s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------16start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.050230116\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            " 85%|████████▌ | 17/20 [18:56<03:20, 66.72s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 0.20107822\n",
            "---------------17start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.055378687\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 0.18486586\n",
            "found better point\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|█████████ | 18/20 [20:09<02:17, 68.52s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------18start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.05147079\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            " 95%|█████████▌| 19/20 [21:13<01:07, 67.14s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 0.18700239\n",
            "---------------19start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.04520352\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "100%|██████████| 20/20 [22:16<00:00, 66.85s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 0.18735504\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.scatter(p_valid['targets'],preds, alpha=0.2)\n",
        "plt.title('Validation Prediction Result')\n",
        "plt.xlabel('Actual')\n",
        "plt.ylabel('Prediction')\n",
        "plt.show()\n",
        "\n",
        "x = np.arange(epochs)\n",
        "plt.title('Validation Losses')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.plot(x,trainlosses)\n",
        "plt.plot(x,vallosses)\n",
        "plt.show()\n",
        "\n",
        "x = np.arange(epochs)\n",
        "plt.title('Validation Scores')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Score')\n",
        "plt.plot(x,trainscores)\n",
        "plt.plot(x,validscores)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Jom5xJUz1QMO",
        "outputId": "f8ad752e-5483-4aef-e900-b94048d86290"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkAAAAHHCAYAAABXx+fLAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABu5UlEQVR4nO3dd3hUVeLG8e9MyqQnhJAmJfRelBLBggVpKqKogOxSrIt90d8qFtB1V8C2WBBcbFhQxIJrAyEKKoQiSFF6r0kgkE7q3N8fNxmIhJJkJpPJvJ/nuU9m7tx77rkZhnlz7rnnWAzDMBARERHxIlZ3V0BERESkpikAiYiIiNdRABIRERGvowAkIiIiXkcBSERERLyOApCIiIh4HQUgERER8ToKQCIiIuJ1FIBERETE6ygAicg52717NxaLhXfffdex7qmnnsJisZzT/haLhaeeesqpdbrsssu47LLLnFqmiNR9CkAiddSgQYMICgoiOzv7tNuMGDECf39/0tPTa7Bmlbdx40aeeuopdu/e7e6qlLN7927GjBlD8+bNCQgIIDY2lksvvZSJEye6u2oichYKQCJ11IgRIzh+/DhffPFFha/n5eXx5Zdf0r9/f+rXr1/l4zzxxBMcP368yvufi40bN/L0009XGIC+//57vv/+e5cevyLbt2/n/PPPZ8GCBQwfPpzXXnuNe+65h/r16zNlypQar4+IVI6vuysgIq4xaNAgQkNDmT17NiNHjjzl9S+//JLc3FxGjBhRreP4+vri6+u+/0r8/f3dctz//Oc/5OTksHbtWpo0aVLutbS0tBqtS25uLsHBwTV6TBFPpxYgkToqMDCQG264gaSkpAq/kGfPnk1oaCiDBg3i6NGjPPzww3Ts2JGQkBDCwsIYMGAA69atO+txKuoDVFBQwN///ncaNGjgOMb+/ftP2XfPnj3cfffdtG7dmsDAQOrXr89NN91UrqXn3Xff5aabbgLg8ssvx2KxYLFYWLx4MVBxH6C0tDRuu+02YmJiCAgIoHPnzsyaNavcNmX9mV544QX++9//0rx5c2w2G927d2fVqlVnPe8dO3bQsGHDU8IPQHR09CnrvvvuO3r37k1oaChhYWF0796d2bNnl9tm7ty5dO3alcDAQKKiovjLX/7CgQMHym0zevRoQkJC2LFjBwMHDiQ0NNQRYu12O1OnTqV9+/YEBAQQExPDXXfdxbFjx8qV8euvv9KvXz+ioqIIDAykadOm3HrrrWc9Z5G6RC1AInXYiBEjmDVrFp988gn33nuvY/3Ro0cdl24CAwP5448/mDdvHjfddBNNmzYlNTWVN954g969e7Nx40bi4+Mrddzbb7+dDz74gFtuuYVevXrxww8/cPXVV5+y3apVq1i2bBnDhg2jYcOG7N69m+nTp3PZZZexceNGgoKCuPTSS7n//vt55ZVXeOyxx2jbti2A4+efHT9+nMsuu4zt27dz77330rRpU+bOncvo0aPJyMjggQceKLf97Nmzyc7O5q677sJisfDcc89xww03sHPnTvz8/E57jk2aNGHRokX88MMPXHHFFWf8fbz77rvceuuttG/fnvHjxxMREcFvv/3G/PnzueWWWxzbjBkzhu7duzNp0iRSU1N5+eWXWbp0Kb/99hsRERGO8oqLi+nXrx8XX3wxL7zwAkFBQQDcddddjnLuv/9+du3axWuvvcZvv/3G0qVL8fPzIy0tjb59+9KgQQMeffRRIiIi2L17N59//vkZz0GkzjFEpM4qLi424uLijJ49e5ZbP2PGDAMwFixYYBiGYeTn5xslJSXlttm1a5dhs9mMf/7zn+XWAcY777zjWDdx4kTj5P9K1q5dawDG3XffXa68W265xQCMiRMnOtbl5eWdUufk5GQDMN577z3Hurlz5xqA8eOPP56yfe/evY3evXs7nk+dOtUAjA8++MCxrrCw0OjZs6cREhJiZGVllTuX+vXrG0ePHnVs++WXXxqA8dVXX51yrJP9/vvvRmBgoAEYXbp0MR544AFj3rx5Rm5ubrntMjIyjNDQUCMxMdE4fvx4udfsdrujftHR0UaHDh3KbfP1118bgDFhwgTHulGjRhmA8eijj5Yr6+effzYA48MPPyy3fv78+eXWf/HFFwZgrFq16oznJ1LX6RKYSB3m4+PDsGHDSE5OLndZafbs2cTExHDllVcCYLPZsFrN/w5KSkpIT08nJCSE1q1bs2bNmkod89tvvwXg/vvvL7f+wQcfPGXbwMBAx+OioiLS09Np0aIFERERlT7uycePjY1l+PDhjnV+fn7cf//95OTksGTJknLbDx06lHr16jmeX3LJJQDs3LnzjMdp3749a9eu5S9/+Qu7d+/m5ZdfZvDgwcTExDBz5kzHdgsXLiQ7O5tHH32UgICAcmWUXTr89ddfSUtL4+677y63zdVXX02bNm345ptvTjn+2LFjyz2fO3cu4eHhXHXVVRw5csSxdO3alZCQEH788UcAR0vS119/TVFR0RnPUaQuUwASqePK+oeU9TfZv38/P//8M8OGDcPHxwcw+4785z//oWXLlthsNqKiomjQoAHr168nMzOzUsfbs2cPVquV5s2bl1vfunXrU7Y9fvw4EyZMoFGjRuWOm5GRUenjnnz8li1bOgJdmbJLZnv27Cm3vnHjxuWel4WhP/ebqUirVq14//33OXLkCOvXr+fZZ5/F19eXO++8k0WLFgFmXyGADh06nLHOUPHvqE2bNqfU2dfXl4YNG5Zbt23bNjIzM4mOjqZBgwbllpycHEc/sN69ezNkyBCefvppoqKiuO6663jnnXcoKCg46/mK1CXqAyRSx3Xt2pU2bdrw0Ucf8dhjj/HRRx9hGEa5u7+effZZnnzySW699VaeeeYZIiMjsVqtPPjgg9jtdpfV7b777uOdd97hwQcfpGfPnoSHh2OxWBg2bJhLj3uyshD4Z4ZhVKqMjh070rFjR3r27Mnll1/Ohx9+SJ8+fZxVzXJObrErY7fbiY6O5sMPP6xwnwYNGgBmq9Onn37K8uXL+eqrr1iwYAG33norL774IsuXLyckJMQldRapbRSARLzAiBEjePLJJ1m/fj2zZ8+mZcuWdO/e3fH6p59+yuWXX85bb71Vbr+MjAyioqIqdawmTZpgt9vZsWNHuRaNLVu2nLLtp59+yqhRo3jxxRcd6/Lz88nIyCi33bmONF12/PXr12O328uFhM2bNzted6Vu3boBcOjQIQBHS9jvv/9OixYtKtynrE5btmw5pUP1li1bzqnOzZs3Z9GiRVx00UXlLi2ezoUXXsiFF17Iv//9b2bPns2IESP4+OOPuf3228+6r0hdoEtgIl6grLVnwoQJrF279pSxf3x8fE5p8Zg7d+4pt2CfiwEDBgDwyiuvlFs/derUU7at6LivvvoqJSUl5daVjXHz52BUkYEDB5KSksKcOXMc64qLi3n11VcJCQmhd+/e53IaZ/Xzzz9X2IemrA9UWfjr27cvoaGhTJo0ifz8/HLblp17t27diI6OZsaMGeUuRX333Xds2rSpwjvo/uzmm2+mpKSEZ5555pTXiouLHb+7Y8eOnfI779KlC4Aug4lXUQuQiBdo2rQpvXr14ssvvwQ4JQBdc801/POf/2TMmDH06tWLDRs28OGHH9KsWbNKH6tLly4MHz6c119/nczMTHr16kVSUhLbt28/ZdtrrrmG999/n/DwcNq1a0dycjKLFi06ZWTqLl264OPjw5QpU8jMzMRms3HFFVdUON7OnXfeyRtvvMHo0aNZvXo1CQkJfPrppyxdupSpU6cSGhpa6XOqyJQpU1i9ejU33HADnTp1AmDNmjW89957REZGOjp9h4WF8Z///Ifbb7+d7t27c8stt1CvXj3WrVtHXl4es2bNws/PjylTpjBmzBh69+7N8OHDHbfBJyQk8Pe///2s9enduzd33XUXkyZNYu3atfTt2xc/Pz+2bdvG3Llzefnll7nxxhuZNWsWr7/+Otdffz3NmzcnOzubmTNnEhYWxsCBA53yuxHxCO68BU1Eas60adMMwOjRo8cpr+Xn5xsPPfSQERcXZwQGBhoXXXSRkZycfMot5udyG7xhGMbx48eN+++/36hfv74RHBxsXHvttca+fftOuQ3+2LFjxpgxY4yoqCgjJCTE6Nevn7F582ajSZMmxqhRo8qVOXPmTKNZs2aGj49PuVvi/1xHwzCM1NRUR7n+/v5Gx44dy9X55HN5/vnnT/l9/LmeFVm6dKlxzz33GB06dDDCw8MNPz8/o3Hjxsbo0aONHTt2nLL9//73P6NXr15GYGCgERYWZvTo0cP46KOPym0zZ84c4/zzzzdsNpsRGRlpjBgxwti/f3+5bUaNGmUEBweftl7//e9/ja5duxqBgYFGaGio0bFjR+Mf//iHcfDgQcMwDGPNmjXG8OHDjcaNGxs2m82Ijo42rrnmGuPXX3894/mK1DUWw6hETz8RERGROkB9gERERMTrKACJiIiI11EAEhEREa+jACQiIiJeRwFIREREvI4CkIiIiHgdDYRYAbvdzsGDBwkNDa3UEPwiIiLiPoZhkJ2dTXx8/Cnz5f2ZAlAFDh48SKNGjdxdDREREamCffv20bBhwzNuowBUgbKh8vft20dYWJibayMiIiLnIisri0aNGp3TlDcKQBUou+wVFhamACQiIuJhzqX7ijpBi4iIiNdRABIRERGvowAkIiIiXkcBSERERLyOApCIiIh4HQUgERER8ToKQCIiIuJ1FIBERETE6ygAiYiIiNdRABIRERGvowAkIiIiXkcBSERERLyOAlANW7b9CMcLS9xdDREREa+mAFSDJn23iVveXMHURVvdXRURERGvpgBUg3okRAIw8+ed/H4g0821ERER8V4KQDXoyrYxXN0pDrsBj3y2nuISu7urJCIi4pUUgGrYU9e2JzzQjz8OZvHWL7vcXR0RERGvpABUwxqE2nj86rYAvLRwK3vSc91cIxEREe+jAOQGN3VtSK/m9SkotvPYFxswDMPdVRIREfEqCkBuYLFYePb6jth8rSzdns6nq/e7u0oiIiJeRQHITRKigvn7Va0A+Nc3mzicXeDmGomIiHiPWhGApk2bRkJCAgEBASQmJrJy5crTbvv555/TrVs3IiIiCA4OpkuXLrz//vvlthk9ejQWi6Xc0r9/f1efRqXdfnFT2seHkXm8iH9+vdHd1REREfEabg9Ac+bMYdy4cUycOJE1a9bQuXNn+vXrR1paWoXbR0ZG8vjjj5OcnMz69esZM2YMY8aMYcGCBeW269+/P4cOHXIsH330UU2cTqX4+liZfEMnrBb4at1BkjalurtKIiIiXsHtAeill17ijjvuYMyYMbRr144ZM2YQFBTE22+/XeH2l112Gddffz1t27alefPmPPDAA3Tq1Ilffvml3HY2m43Y2FjHUq9evZo4nUrr2DCc2y9pBsAT834np6DYzTUSERGp+9wagAoLC1m9ejV9+vRxrLNarfTp04fk5OSz7m8YBklJSWzZsoVLL7203GuLFy8mOjqa1q1bM3bsWNLT009bTkFBAVlZWeWWmvT3Pq1oHBnEocx8np+/uUaPLSIi4o3cGoCOHDlCSUkJMTEx5dbHxMSQkpJy2v0yMzMJCQnB39+fq6++mldffZWrrrrK8Xr//v157733SEpKYsqUKSxZsoQBAwZQUlLxJKSTJk0iPDzcsTRq1Mg5J3iOAv19+Pf1HQB4b/keVu85VqPHFxER8TZuvwRWFaGhoaxdu5ZVq1bx73//m3HjxrF48WLH68OGDWPQoEF07NiRwYMH8/XXX7Nq1apy25xs/PjxZGZmOpZ9+/bVzImc5JKWDRhyQUMMAx79bD2FxZomQ0RExFXcGoCioqLw8fEhNbV859/U1FRiY2NPu5/VaqVFixZ06dKFhx56iBtvvJFJkyaddvtmzZoRFRXF9u3bK3zdZrMRFhZWbnGHJ65uS/1gf7al5TB98Q631EFERMQbuDUA+fv707VrV5KSkhzr7HY7SUlJ9OzZ85zLsdvtFBScfhyd/fv3k56eTlxcXLXq62r1gv2ZcG07AKb9uJ3tadlurpGIiEjd5PZLYOPGjWPmzJnMmjWLTZs2MXbsWHJzcxkzZgwAI0eOZPz48Y7tJ02axMKFC9m5cyebNm3ixRdf5P333+cvf/kLADk5Ofzf//0fy5cvZ/fu3SQlJXHdddfRokUL+vXr55ZzrIxBneO5vHUDCkvsPPrZBux2TZMhIiLibL7ursDQoUM5fPgwEyZMICUlhS5dujB//nxHx+i9e/ditZ7Iabm5udx9993s37+fwMBA2rRpwwcffMDQoUMB8PHxYf369cyaNYuMjAzi4+Pp27cvzzzzDDabzS3nWBkWi4V/Xd+Rq15awq97jvHhyr389cIm7q6WiIhInWIxNBPnKbKysggPDyczM9Nt/YHeWbqLp7/aSIjNl0XjehMbHuCWeoiIiHiKynx/u/0SmFRsZM8EujSKIKegmCfm/a4Z40VERJxIAaiW8rFamDKkE75WC4s2pfLd76cfF0lEREQqRwGoFmsdG8rdlzUHYOL//iAzr8jNNRIREakbFIBqubsvb0GzBsEczi5g0neb3F0dERGROkEBqJYL8PNh8g2dAPh41T6W7Tji5hqJiIh4PgWgmmYYUHz6QRsr0qNpJCMSGwPw2OcbyC+qeE4zEREROTcKQDVp+XR4sTUsfaXSuz4yoA0xYTZ2p+fxStI2F1RORETEeygA1SSrL+Skwp5fKr1rWIAf/7zOnDH+jZ92svFglrNrJyIi4jUUgGpSk4vMn/tWQknl7+jq1z6WAR1iKbEbPPr5eko0TYaIiEiVKADVpAZtIDASivLg4G9VKuLpQe0JDfBl/f5M3lm6y8kVFBER8Q4KQDXJaoUmvczHuyt/GQwgOiyAxwa2BeDF77ey72ies2onIiLiNRSAalrCxebPPUurXMTQbo1IbBrJ8aISHvtig6bJEBERqSQFoJpW1g9o73IoKa5SEVarhUk3dMTf18rP244wb+0BJ1ZQRESk7lMAqmkx7SEgHApzIGVdlYtp1iCEB65sCcA/v9pIek7lxhYSERHxZgpANc3qA43L+gFV/TIYwJ2XNqNNbCjH8op45uuNTqiciIiId1AAcoeE0stg1egHBODnY2XykE5YLTBv7UEWb0lzQuVERETqPgUgdyjrB7QnGezVm9aiS6MIRvdqCsDjX/xObkHV+hWJiIh4EwUgd4jtBP6hUJAJqb9Xu7iH+rbivIhADmQc58XvtzqhgiIiInWbApA7+PhC4wvNx9XsBwQQbPPl39eb02S8u2yXpskQERE5CwUgd3FSP6Ayl7WOpl/7GOwGfL5mv1PKFBERqasUgNylyUkDItrtTiny+vMbAvDd7ykaHFFEROQMFIDcJb4L+AXB8WNweJNTirysdQOC/H04kHGc9fsznVKmiIhIXaQA5C4+ftCoh/nYCf2AAAL8fLi8dTRgtgKJiIhIxRSA3MlxGaxqE6NWZEDHWAC++/2QLoOJiIichgKQOzk6Qi8DJ4WVy1tHY/O1sic9j02Hsp1SpoiISF2jAORO53UF3wDIPQxHnDN+T7DNl96tGgBmK5CIiIicSgHInXxt0LC7+Xi38y6DDewYB8C3GxSAREREKqIA5G5NnDseEMAVbaPx87Gw43Au21J1GUxEROTPFIDcrawf0O6lTusHFBbgxyUtzctg327Q3WAiIiJ/pgDkbg27g48/5KTA0Z1OK7Z/hxN3g4mIiEh5CkDu5hdodoYGp14G69suBl+rhc0p2ew8nOO0ckVEROoCBaDaoMlJl8GcJCLIn57N6wMaFFFEROTPFIBqAydPjFpmQAfzbrD5CkAiIiLlKADVBo0SweoLmfvg2B6nFdu3fQxWC2w4kMm+o3lOK1dERMTTKQDVBv7BEH+++diJrUBRITZ6NI0E1AokIiJyMgWg2sIF/YDgpEERdTeYiIiIgwJQbZHg/IlRAfq1j8Vigd/2ZnAo87hTyxYREfFUCkC1RaNEsFjh2G7IPOC0YmPCAujauB6gy2AiIiJlFIBqi4AwiOtsPnb23WCll8G+06jQIiIigAJQ7eLoB+Tcy2Blo0Kv2nOUtOx8p5YtIiLiiRSAahNHPyDntgCdFxFI50YRGAYs+CPVqWWLiIh4IgWg2qRxT8AC6dsh27mXqwaWzQ22QXeDiYiI1IoANG3aNBISEggICCAxMZGVK1eedtvPP/+cbt26ERERQXBwMF26dOH9998vt41hGEyYMIG4uDgCAwPp06cP27Ztc/VpVF9gBMR2MB+7aFToFbuOkp5T4NSyRUREPI3bA9CcOXMYN24cEydOZM2aNXTu3Jl+/fqRlpZW4faRkZE8/vjjJCcns379esaMGcOYMWNYsGCBY5vnnnuOV155hRkzZrBixQqCg4Pp168f+fke0P+lSellMCePB9S4fhDt48MosRss3KjLYCIi4t3cHoBeeukl7rjjDsaMGUO7du2YMWMGQUFBvP322xVuf9lll3H99dfTtm1bmjdvzgMPPECnTp345Rez47BhGEydOpUnnniC6667jk6dOvHee+9x8OBB5s2bV4NnVkUumhcMTgyKqMlRRUTE27k1ABUWFrJ69Wr69OnjWGe1WunTpw/Jycln3d8wDJKSktiyZQuXXnopALt27SIlJaVcmeHh4SQmJp62zIKCArKyssotbtO4l/nz8GbIPeLUosvuBlu6/QiZeUVOLVtERMSTuDUAHTlyhJKSEmJiYsqtj4mJISXl9K0UmZmZhISE4O/vz9VXX82rr77KVVddBeDYrzJlTpo0ifDwcMfSqFGj6pxW9QTXh+h25mMntwI1bxBC65hQiu0GCzfpMpiIiHgvt18Cq4rQ0FDWrl3LqlWr+Pe//824ceNYvHhxlcsbP348mZmZjmXfvn3Oq2xVuGheMDjRCjRfc4OJiIgXc2sAioqKwsfHh9TU8q0RqampxMbGnnY/q9VKixYt6NKlCw899BA33ngjkyZNAnDsV5kybTYbYWFh5Ra3qoF+QD9tPUJ2vi6DiYiId3JrAPL396dr164kJSU51tntdpKSkujZs+c5l2O32ykoMG/tbtq0KbGxseXKzMrKYsWKFZUq063KWoBS/4C8o04tulVMCM0aBFNYYueHzRXfaSciIlLXuf0S2Lhx45g5cyazZs1i06ZNjB07ltzcXMaMGQPAyJEjGT9+vGP7SZMmsXDhQnbu3MmmTZt48cUXef/99/nLX/4CgMVi4cEHH+Rf//oX//vf/9iwYQMjR44kPj6ewYMHu+MUKy8kGqJaAQbsPXtn8MqwWCwMcAyKqLvBRETEO/m6uwJDhw7l8OHDTJgwgZSUFLp06cL8+fMdnZj37t2L1Xoip+Xm5nL33Xezf/9+AgMDadOmDR988AFDhw51bPOPf/yD3Nxc7rzzTjIyMrj44ouZP38+AQEBNX5+VdbkIjiy1ewH1OZqpxY9oEMc037cweKtaeQVFhPk7/Z/BiIiIjXKYhiG4e5K1DZZWVmEh4eTmZnpvv5AGz6Fz24zZ4i/6yenFm0YBr2fX8zeo3m8PuICR78gERERT1aZ72+3XwKT0yjrB5SyAfIznVr0yZfBvtXcYCIi4oUUgGqrsDiIbAaGHfYud3rxA0pbfX7cnEZ+UYnTyxcREanNFIBqM8d4QL84vejODcOJDw8gt7CEn7Yednr5IiIitZkCUG3WxHXjAVksFvp30NxgIiLinRSAarOyAREProWCbKcXP7Cj2Q9o0aZUCop1GUxERLyHAlBtFtEYwhuDUQL7Vji9+Asa1yM61EZ2fjHLtqc7vXwREZHaSgGotktw3bxgVqvFMTfYd5obTEREvIgCUG3nwn5AcGJy1O83plJUYnfJMURERGobBaDarqwF6MAaKMxzevE9EiKpH+xPRl4Ry3fqMpiIiHgHBaDarl5TCI0HexHsX+n04n19rPRtX3YZTHeDiYiId1AAqu0sFpf2AwIco0J//0cKJXbNjCIiInWfApAncHE/oJ7N6xMe6MeRnEJW7T7qkmOIiIjUJgpAniDhYvPn/l+hKN/pxfv5WOnbLgaA7zQ3mIiIeAEFIE9QvwUER0NJARxY7ZJDDOh4oh+QXZfBRESkjlMA8gQn9wNy0WWwi1pEEWrzJS27gN/2HXPJMURERGoLBSBP4cKJUQFsvj5c2TYagG836G4wERGp2xSAPEVZP6B9K6G40CWHGNDRnBx1/u8pGIYug4mISN2lAOQpGrSBoPpQfBwO/uaSQ/Ru1YAgfx8OZBxn/f5MlxxDRESkNlAA8hQWCzTpZT7e45rLYAF+PlzepvQymOYGExGROkwByJM0Kb0M5qIBEQEGdtBlMBERqfsUgDxJ2Z1g+1ZASbFLDnFZ6wbYfK3sSc9j46EslxxDRETE3RSAPEl0ewiIgMIcOLTOJYcItvlyWesGgNkKJCIiUhcpAHkSq9Xl/YAABpbeDfbNhkO6DCYiInWSApCnaeLaiVEBrmgTjb+PlZ2Hc9mWluOy44iIiLiLApCnKesHtDcZ7CUuOURogB+XtIwC4DsNiigiInWQApCnie0EtjAoyIKUDS47TNmgiN/pdngREamDFIA8jdUHGl9oPnbRvGAAV7WNwddqYXNKNjsP6zKYiIjULQpAnqgG+gGFB/nRq0XpZTDdDSYiInWMApAnKpsXbO8ysNtddpgBHWIBXQYTEZG6RwHIE8V1Br9gOH4M0ja67DB928VgtcDvB7LYdzTPZccRERGpaQpAnsjHDxonmo9d2A+ofoiNC5vVB9QKJCIidYsCkKdy9ANy3YCIcPJlMPUDEhGRukMByFOV9QPaswxcOFpzv/axWCzw294MDmYcd9lxREREapICkKeKvwB8AyHvCBze4rLDRIcF0K1JPUBzg4mISN2hAOSpfP2hUXfzsQvnBQMY0MEcFFEBSERE6goFIE/WpPQymAvHAwLoX9oPaNWeo6Rl57v0WCIiIjVBAciTlc0LtmepS/sBxUcE0qVRBIYBC/5IddlxREREaooCkCc7rxv4+ENOKqTvcOmhBnYsvRtsg26HFxERz6cA5Mn8AswQBDXWD2j5znQy84pceiwRERFXUwDydAmunxcMoFFkEM0aBGM3YNXuoy49loiIiKspAHm6JjXTDwggsWkkACsVgERExMMpAHm6Rj3A6gtZB+DYbpceqkdpAFqxSwFIREQ8W60IQNOmTSMhIYGAgAASExNZuXLlabedOXMml1xyCfXq1aNevXr06dPnlO1Hjx6NxWIpt/Tv39/Vp+Ee/sHmoIjg0nnBAHo0NecF+/1AJrkFxS49loiIiCu5PQDNmTOHcePGMXHiRNasWUPnzp3p168faWlpFW6/ePFihg8fzo8//khycjKNGjWib9++HDhwoNx2/fv359ChQ47lo48+qonTcY8a6gd0XkQg50UEUmI3WLP3mEuPJSIi4kpuD0AvvfQSd9xxB2PGjKFdu3bMmDGDoKAg3n777Qq3//DDD7n77rvp0qULbdq04c0338Rut5OUlFRuO5vNRmxsrGOpV69eTZyOe5QNiOjiO8EAEpuV9gPSZTAREfFgbg1AhYWFrF69mj59+jjWWa1W+vTpQ3Jy8jmVkZeXR1FREZGRkeXWL168mOjoaFq3bs3YsWNJT093at1rlcaJYPGBjL2Qsc+lh0pUPyAREakD3BqAjhw5QklJCTExMeXWx8TEkJJybvNOPfLII8THx5cLUf379+e9994jKSmJKVOmsGTJEgYMGEBJSUmFZRQUFJCVlVVu8Si2UIjrbD6uoX5Aa/dlkF9U8e9TRESktnP7JbDqmDx5Mh9//DFffPEFAQEBjvXDhg1j0KBBdOzYkcGDB/P111+zatUqFi9eXGE5kyZNIjw83LE0atSohs7AiRz9gFx7GSyhfhANQm0UFttZvz/TpccSERFxFbcGoKioKHx8fEhNLT+/VGpqKrGxsWfc94UXXmDy5Ml8//33dOrU6YzbNmvWjKioKLZv317h6+PHjyczM9Ox7Nvn2stILuHoB+TaFiCLxeK4HX7lrjp8WVFEROo0twYgf39/unbtWq4Dc1mH5p49e552v+eee45nnnmG+fPn061bt7MeZ//+/aSnpxMXF1fh6zabjbCwsHKLx2l8IWCBozshy7XzdakfkIiIeDq3XwIbN24cM2fOZNasWWzatImxY8eSm5vLmDFjABg5ciTjx493bD9lyhSefPJJ3n77bRISEkhJSSElJYWcnBwAcnJy+L//+z+WL1/O7t27SUpK4rrrrqNFixb069fPLedYIwIjIK60JWzz1y49VFkL0Oo9xygusbv0WCIiIq7g9gA0dOhQXnjhBSZMmECXLl1Yu3Yt8+fPd3SM3rt3L4cOnWjRmD59OoWFhdx4443ExcU5lhdeeAEAHx8f1q9fz6BBg2jVqhW33XYbXbt25eeff8Zms7nlHGtM51vMn0tfhuJClx2mVXQo4YF+5BWW8MdBD+swLiIiAlgMw8UTSHmgrKwswsPDyczM9KzLYUXH4eXOkJMK10yFbmNcdqjbZ/3Kok2pPD6wLXdc2sxlxxERETlXlfn+dnsLkDiRXyBc/Hfz8c8vubQV6EQ/IHWEFhERz6MAVNd0HQ0hMZC5F9a5bvqPE3eCHcVuVyOiiIh4FgWgusYvEC56wHz88wtQUuSSw7SPDyPI34es/GK2pGa75BgiIiKuogBUF3UdA8HR5tQYLmoF8vWx0rWJOb+a5gUTERFPowBUF/kHnWgF+sl1rUCJTTUxqoiIeCYFoLqq260Q3AAy9sC6j11yiLJ5wVbsOopuJhQREU+iAFRX+QdBr/vNxy7qC9SpYTj+vlaO5BSw60iu08sXERFxFQWguqz7bRAUBcd2w/pPnF58gJ8P5zeKAHQZTEREPIsCUF3mHwwXlbYC/fQ8lBQ7/RDqByQiIp5IAaiu6347BNWHY7tgg/NbgU7uByQiIuIpFIDqOv/gE32BXNAKdEGTCHytFg5kHGf/sTynli0iIuIqCkDeoKwV6OhO+P1TpxYd5O9Lh/PCAVi1W61AIiLiGXzdXQGpAbYQ6HkvJD0NS56DDjeCj/Pe+sSmkazdl8HKXUe5/vyGTitXPERJMeQeNifhLVuyyx6nQE4aFOfDtS9D/Pnurq2ICKAA5D163AHLXoWjO+D3z6DzUOcV3TSSN37aqX5AdU1BzkmBpjTIlAWak5/nHgHOYRyoL++FO5c4NXyLiFSV/ifyFrZQ6HUvJP0TfnoOOt4IVh+nFN2tSSQWC+w8nMvh7AIahNqcUq7UkMI8SH4NUv84EWqyU6GoEmM7Wazm9CuhMeZkvGVLaCwERcI3D0Hq77BqJlw41nXnIiJyjhSAvEmPO81WoPTtZitQp5udUmx4kB9tYsPYdCiLVbuPMrBjnFPKlRpgGPDl3fDHFxW/7hdcQagpexwLIdGlIaf+mQN1fhZ8/SD88G9of725j4iIGykAeRNbqNkX6IdnSvsCDXFaK1Bi00g2Hcpixc50BSBPkjzNDD9WX7j8caiXYIaTsrBjC3HOcS4YBb+9DwdWw/dPwpCZzilXRKSKdBeYt+lxJwREQPq20//VX5ViSwdEVD8gD7LrZ1g4wXzcbxJcMg463ABNekH95s4LPwBWKwx8AbCY41Ht+tl5ZYuIVIECkLcJCDNbgQCWTAF7iVOK7Z5gBqAtqdlk5BU6pUxxocwDMHc0GCXQaZjZSd7VzrvAnKQX4NuHXTI/nYjIuVIA8kaJpa1AR7Y6rRWoQaiNZg2CMQz4dfcxp5QpLlJcAJ+MhLwjENMRrvkPWCw1c+wrnjD7Cx3eDMun18wxRUQqoADkjQLCoec95uOfnge73SnFOuYF04CItdt3j8CBX80QPPR98A+quWMHRcJV/zQfL55stkSJiLiBApC3SrzLDEKHN8PGeU4pUv2APMBvH8DqdwALDHkTIpvWfB063wINe5i32X//eM0fX0QEBSDvFRAOF5a2Ai15zimtQImlE6P+fiCT3ALnzzwv1XTwN/h6nPn48seg5VXuqYfVCle/aI4d9McXsONH99RDRLyaApA3S7wLbOFweBNs+rLaxcVHBNKwXiAldoM1e9UPqFbJTYc5f4WSAmg1AC552L31ietk3pEIZofo4gL31kdEvI4CkDcLjDgxKq+TWoHKLoOt1GWw2sNeAp/dCpn7ILIZXD/DbIVxt8sfM0ePTt9ujkQtIlKDasH/guJWF/4NbGGQthE2/a/axSWqH1Dt88O/YOdi8AuCoR+awbc2CAiHvv8yHy95HjL2ubc+IuJVFIC8XWA9p7YC9SjtB7R2Xwb5Rc4ZY0iqYdNX8MtL5uNBr0JMO/fW58863QxNLoLi4zD/UXfXRkS8SLUCUGFhIVu2bKG4WB1ePdqFY0tbgf6AzV9Xq6iE+kE0CLVRWGxn/f5MJ1VQquTwVviiNNxeeI85AW5tY7GYI0RbfMx/e9sWurtGIuIlqhSA8vLyuO222wgKCqJ9+/bs3bsXgPvuu4/Jkyc7tYJSAwLrmR2ioXR06Kq3AlkslpP6AaU7o3ZSFQXZMGcEFGabLSxXPe3uGp1eTLsTrZDf/h8U5bu3PiLiFaoUgMaPH8+6detYvHgxAQEBjvV9+vRhzpw5Tquc1KAL7wb/UEj9HbZ8U62i1A/IzQwD5t1tjvQdGgc3vQs+fu6u1Zld9qhZ12O7YNkr7q6NiHiBKgWgefPm8dprr3HxxRdjOWkI/fbt27Njxw6nVU5qUFBk+VYgw6hyUWUtQKv3HKO4xDmjTDtFcSGUeMHl2mWvmB3arX5w8/sQEu3uGp2dLfREh+ifX4Rju91aHRGp+3yrstPhw4eJjj71P9Xc3NxygUg8TM97YMUMSNkAm7+BttdUqZhW0aGEB/qRebyIPw5m0blRhHPrWRWr3jQvrxh2cwA+3wDw8Td/+pb+9LGB78lLRduUPS/d5uR9QuOgaW/33mK+czEsesp8PGAyNOruvrpUVochsGYW7PoJvnsUbvnY3TUSkTqsSgGoW7dufPPNN9x3330AjtDz5ptv0rNnT+fVTmpWWSvQzy+arUBtrq7SJJlWq4XuCZEs2pTKyl1H3R+A9i43578ySlujDDsU5ZmLs8V1Mee6atbb+WWfTcY++PRW8/y6jIBut9V8HaqjrEP09Itg63ew5TtoPcDdtRKROqpKAejZZ59lwIABbNy4keLiYl5++WU2btzIsmXLWLJkibPrKDWp572w4g1IWW9+AbUZWKViEpuaAWjFrnTuuLSZkytZCdmp8MkosBebLQwDX4CSQijONy+JFeef9LzAXEoKTjx2PM+vYN3JSz7sWwmH1sJ7g6DFVWbH45j2NXOeRfnwyV8hLx3iOpdONeGBrbENWpstkUunwnf/gGaXgV+gu2slInVQlQLQxRdfzLp165g0aRIdO3bk+++/54ILLiA5OZmOHTs6u45Sk4Iioccd8Mt/YMlk8y/wKnyRnjwitN1uYLW64cu4pAg+HQM5KdCgDVz7CthCXHe8nMPw03Pw69uwfSFsXwRdbjFHPA5v6LrjAnz3f+ZcX4H1zH4/nhwaLv0/2DAXMvbCzy/BFZowVUScr9KdFYqKirj11luxWCzMnDmTlStXsnHjRj744AOFn7qi533gFwyH1sHW+VUqon18GEH+PmTlF7MlNdvJFTxHi56CPUvNu9uGfuDa8AMQ0gAGPg/3rIR2gwED1n4Ir3aFhRPheIZrjrv6XVjzHuYM729BvSauOU5NsYVA/0nm46VTIV03VoiI81U6APn5+fHZZ5+5oi5SWwTXN1uBABZPrtIdYb4+Vro2qQe4aV6wP+admF9q8OsQ1bLmjl2/Odw8C25PKh3lON/8In+lCyRPc+7En/tXm527Aa54Alpc6byy3antIGh+hXl58rt/VOuuRBGRilTpdpXBgwczb948J1dFapVe95lzRx1aC9u+r1IRie6aGPXwFvjyHvNxr/uh3aCaPX6Zht1g9Dcw/GPzEtzxY7DgMXitG6yfW/3JZ3OPwCcjzZDQ5hq4eJxz6l0blHWI9vE3LyVWc4RyEZE/q1IfoJYtW/LPf/6TpUuX0rVrV4KDg8u9fv/99zulcuJGwVFmK9DSl2HxJGjZt9J9gRKbmfOCrdh1FMMwamaIhIIcmPNXKMyBhEvgyomuP+aZWCxmP6oWV8G62fDjs2bfls9vh+RXS+8Yu6zy5ZYUm/2bsvZD/RYweHrtmOHdmeo3NwPszy+Yt8U3vwL8g8++n4jIObAYRuXblps2bXr6Ai0Wdu7cWa1KuVtWVhbh4eFkZmYSFhbm7uq4T+4RmNrRvF38lrnQqm+ldi8oLqHjU99TWGznh4d606yBi/vgGIYZCv74whyT566fat8ggIV5sPx1+GWqOU0FQIs+0OdpiO1w7uV8/6Q54KFfMNzxA0S3cUl13a4wD6YlQuZeuPjv0Ocpd9dIRGqxynx/V+lPxl27dp128fTwIycJjoLupWPJLKl8XyCbrw/nl44BVCOXwZZPN8OP1RdumlX7wg+AfxBc+jA8sBZ63GXWdfsimHGxOXFp5v6zl/HHFyemixg8re6GHzB/XwNK5xdc9po5wauIiBNUu83cMAyq0IgknqLXA+AbCAdWm1/UlVRj/YD2LIPvnzAf93sWGie69njVFRwFA58z7xhrfz1gmJfIXrkAFk44/R1jaZthXln/pvtK963jWg+Elv3AXgTfPqwO0SLiFFUOQO+99x4dO3YkMDCQwMBAOnXqxPvvv+/MukltENLgRCtQFe4I69H0RD8gl8lOgbmjwSiBjjdBjztddyxnq9/cnKz09h+gycXmAItLXzbvGFv2Wvk7xvKzzBnei3JL+zc95aZK1zCLxWwF8rHBriVmC5iISDVVKQC99NJLjB07loEDB/LJJ5/wySef0L9/f/72t7/xn//8p9LlTZs2jYSEBAICAkhMTGTlypWn3XbmzJlccskl1KtXj3r16tGnT59TtjcMgwkTJhAXF0dgYCB9+vRh27Ztla6XlLqorBXoV9iRVKldL2gSga/VwoGM4+w/5oKpJ0qKYO4YyEmF6HZw7cueOQJyw64w+mu45RNo0Na8Y+z7x0vvGPsE7CUwbyykb4ew8+DGd8CnSvcweKbIZnBJ6V1uCx6DAjeNLSUidUaVAtCrr77K9OnTmTJlCoMGDWLQoEE899xzvP7667zyyiuVKmvOnDmMGzeOiRMnsmbNGjp37ky/fv1IS0urcPvFixczfPhwfvzxR5KTk2nUqBF9+/blwIEDjm2ee+45XnnlFWbMmMGKFSsIDg6mX79+5OfnV+V0JST6RCvQD/82O6aeoyB/XzqcFw7Aqt0uaAVaOBH2LgNbmDkCsiffJWSxQKt+MHYpDHrN7MidsRc+v8PsjL75a/O28JvfN1vmvM1FD0K9BMg+ZM5VJ1KbFRfAsT3uroWciVEFNpvN2LZt2ynrt27dathstkqV1aNHD+Oee+5xPC8pKTHi4+ONSZMmndP+xcXFRmhoqDFr1izDMAzDbrcbsbGxxvPPP+/YJiMjw7DZbMZHH310TmVmZmYagJGZmVmJM6njslIM41+xhjExzDBe7WYYh9af867PfrPRaPLI18ajn61zbp02fGbWZ2KYYWz8n3PLrg0Kcg3jpxcM49mGJ87z13fcXSv32rLA/D08HWkYqRvdXRuRiu371TBe7mL+W/16nGEU5rm7Rl6jMt/fVWoBatGiBZ988skp6+fMmUPLluc+4m5hYSGrV6+mT58+jnVWq5U+ffqQnJx8TmXk5eVRVFREZKTZ2XbXrl2kpKSUKzM8PJzExMTTlllQUEBWVla5Rf4kNMa8PBMSC0e2wswrzLuuzqFPUNm8YE7tB3R4C3x5r/n4ogeh7bXOK7u28A+CSx6C+9fCpf+AAc9B19HurpV7teprDvpoL4Zv1CFaapmSYljyHLx1FRwtvSN61Zvm/5dpm9xbNzlFlToRPP300wwdOpSffvqJiy66CIClS5eSlJRUYTA6nSNHjlBSUkJMTEy59TExMWzevPmcynjkkUeIj493BJ6UlBRHGX8us+y1P5s0aRJPP/30OdfbazW9BMYug//dC1u+hfmPwo4f4LrXz3hJpluTSCwW2Hk4l8PZBTQItVWvHgXZMOcvJzoDX/Fk9cqr7YLra0LQk/WfBNuTYM8v5qSpnW52d41E4Nhu+Pwu2LfcfN7+Bmg/GL55CNI2wn8vN//tdh3tmf0U66AqtQANGTKEFStWEBUVxbx585g3bx5RUVGsXLmS66+vudtyJ0+ezMcff8wXX3xBQEBAlcsZP348mZmZjmXfvn1OrGUdE1wfhs0unabAZk6TMb2X+YV0GuFBfrSJNQekqnY/IMMwp7k4shVC472vM7BARGNzLCUwhz7Iz3RvfcS7GQas/QimX2yGH/9QuP4NuPFtaHed+Udj8yuh+Dh8/SDMHWXe5CBuV+Xb4Lt27coHH3zA6tWrWb16NR988AHnn39+pcqIiorCx8eH1NTUcutTU1OJjY09474vvPACkydP5vvvv6dTp06O9WX7VaZMm81GWFhYuUXOwGIxp8m4c7F5x1JuGnxwAyx4HIoLK9ylbDygFTvTq3fs5Gmw8Uuw+pkTjnpjZ2Axx0Cq38K8++/HSe6ujXir48fg01th3t/Mkd0bXQhjf4HOw0608oREw4hP4apnzIFPN34JMy6BvcvdW3epWgD69ttvWbBgwSnrFyxYwHfffXfO5fj7+9O1a1eSkk60HtjtdpKSkujZs+dp93vuued45plnmD9/Pt26dSv3WtOmTYmNjS1XZlZWFitWrDhjmVIFMe3gzh+h++3m8+TX4K0+cGT7KZs6pR/Q7qXmIIFgNiU36lH1ssSz+drMPlEAK9+AlA3urY+3StsMWxfAgTWQecAclsJb7PrZbPX543Ow+MDlT5iTH9dLOHVbqxUuuh9u+x7qNYXMffDOALO/kL2kxqsupipdO3j00UeZPHnyKesNw+DRRx9lwIAB51zWuHHjGDVqFN26daNHjx5MnTqV3NxcxowZA8DIkSM577zzmDTJ/CtvypQpTJgwgdmzZ5OQkODo1xMSEkJISAgWi4UHH3yQf/3rX7Rs2ZKmTZvy5JNPEh8fz+DBg6tyunImfoFw9YvmRJVf3gOH1sEbl5qjHHcZ4fgrqHuCGYC2pGaTkVdIRJB/5Y6TdeikwQ5vPhG6xHu1uNK8xLDxS/jqATMQxXXRJVFXKzpuDkb56zuwv4Ix24LqQ0iM2fJR7ufJSzQE1vPMvjDFhfDjv2DpK4BhjlF1w5vmWF5nc15X+NvPZr+g9XPgx3/DziVww38h/DyXV13Kq9L/FNu2baNdu3anrG/Tpg3bt5/61/+ZDB06lMOHDzNhwgRSUlLo0qUL8+fPd3Ri3rt3L9aTZrmePn06hYWF3HjjjeXKmThxIk899RQA//jHP8jNzeXOO+8kIyODiy++mPnz51ern5CcRZurIf58+OIu2PWTGYa2L4JrpkJgBA1CbTRrEMzOw7n8uvsYfdrFnLVIh5IiM/zkpkF0e7h2qmf+xynO128SbFtkTtXy5pXmeFAJl0Czy8wlqqX+rThL2mZY/Q6s++hEvyurr3kZPC/d/Hzai83Heelmx98zsfqVD0ihMRUEpmgIbwRWH9ef37k4vAU+ux1S1pvPz/8r9J8MtkpM9GwLNQNP8yvMILTnF5hxEVw3zfx/VGpMlWaDj42NZfbs2VxxxRXl1i9atIhbbrnltIMYegrNBl8N9hJzKocf/23+ZxjeGIbMhMYXMv7z9Xy0ch93XtqMxwa2Pfcy5483Z1C3hZn9juo3d1n1xQPtSYbl08zg/ecO0aHxpWGoNzTtDWFxbqmixyrKh03/M1t79i47sT6iMVwwygwAoaV/zNjtZp+YnFTISYGctNLHZT9LH2enQH7GudchJMac4qbzMIjt6NTTO2eGAb++BQueMDszB9aDQa9Wf/iN9B1mH6JDa83nPe40+wr56Y/1qqrM93eVAtBdd91FcnIyX3zxBc2bm19G27dvZ8iQIXTv3p0333yzajWvJRSAnGD/avjsVvPWUIsVej/Kl6HDeGDu73RuFMGX91x0buX8/pn5HwSYd5/pLyQ5HXuJ+UWycwnsXGx2Mi0pKL9NgzYnWoeaXAQB+nxX6Mg2WP0urJ0Nx0v77Vl8oPUA6DrGbL2wVvkeGnOU5Jy0P4Wj1FMDU3Zq+fcwpgN0GmoGopoKszmHzaE/ts43nze7HAZPd97xiwsh6WmzDyWYrdw3vQMNWjunfC/j8gCUmZlJ//79+fXXX2nYsCEA+/bt49JLL+Xzzz8nIiKiShWvLRSAnCQ/C779P1j/MQAF8YlcvnMEqdYGrJ/Yl2DbWa7Apm02BxAryoWL/w59nnJ9naXuKDpuhqCdi81JVA+uBU76787iAw27mS1DzS6Dht3Bt5J90+qS4gLY9JUZfHb/fGJ9WEO4YCRc8FcIi6/hOhXC9oWw7mMzgJSU3mVqsZrvWefh5h9FrpoCZ+v38OXdkHvYHPajz1OQ+Lfqhb/T2bbIvJss97A59+KAKebvXZdwK8XlAQjMDs8LFy5k3bp1BAYG0rlzZy655JIqVbi2UQBysvWfwNfjoDCbbIL5R+Ht3DLmPi5peYZb2POzzPCTvs38gvrL5+rcKtWTd9T8Yt+52FzKRuot4xdktgqVtRBFt3PNF11tc3SnGXp++xDyjpjrLFZo2dds7Wl5Ve3og5N3FDbOM8PQvhUn1vuHmJeiOg8z+385o66FebDwSXMUZzD/LQx5E2LaV7/sM8lONftR7vzRfN5usDnBc2CEa49bh7gsACUnJ5Oens4111zjWDdr1iwmTpxIXl4egwcP5tVXX8Vmq+ZIv26mAOQCR3eanQcPrAZgQ/QgOt4+o+K/3AwDPhlp9j0IOw/u+gmCo2q4wlLnZew9cbls5+ITX/5lgqLMvkPNLjNvbTbs5mU2wzDvRnQ8t5/03P6n5ye/blSwfQlgQHAD8996eCPzbiBXT+pbUgSbvzE7Ne9cfGJ9aJzZ6nD+XyGikWvrUB3pO8w/rNZ/bF5mLxMab44M3nkYRFein+HJDq2Dz+6AI1vM54ljzZafmuqXY7dD8quQ9M+T+lG+CY0Ta+b4Hs5lAWjAgAFcdtllPPLIIwBs2LCBrl27MmrUKNq2bcvzzz/PXXfd5bgby1MpALlISREbZ4+nzfY3sVoMqN8SbnwL4jqX327pK+ZfX1Y/uHW+eZlCxJXsdvOupbIwtGeZeenVXQIiILyhuYSdZ4aisNLn4eeZX/RVuVx3bA+smQW/fWD2sQHAYg4p0HUMtOrvWS2thmG2Bq372ByP5+RO8HGdodMw6HijeTfZ2TiCxzNgLzI7Xw+ebv5u3KFcP0ofuHw8XDyudrTG1WIuC0BxcXF89dVXjsEHH3/8cZYsWcIvv/wCwNy5c5k4cSIbN57l9sdaTgHIdXYdyeWxl6Yx1e91YizHwMe/9Lr6WPNyw+5fYNYg8y/kq1/UeD/iHsWFcODX0v5DP5l3N1ms5heRxWJ+CTmeW096bv3T87LXrafZ3gcwzDCSeQAy95sjCp+VxfxSDzvv1KAU3sh8HBJjHrek2Ow/s/qd0ilrSv/LD442+/VcMArqNXHd77KmFOXDtgVmGNr2vdl6AubvuMWVZqtQ64Hm2GV/lrkfvvjbib5Pba6Ba18xp/5xp/ws+GacOecdmJf4bviva/tilRSZHdFz08zfqb24dCk56fGf1xWdZpuzPG9xFbS95ux1qgSXBaCAgAC2bdtGo0Zm0+jFF1/MgAEDePxxc6LG3bt307FjR7Kzz+UDXHspALmOYRj0eDaJouwj/NjyU+rtW2i+0KIPXDkBPrjR/OB1GgbXz1AHQPE++ZlmGMoqDURlPx2PD5x6d1tFrL5mS1FxvvmZKtPsMuh2qxkGfPxcdhpulZtutgit+8hx2R0wh9Jod50Zhhr3MgPi75+bc3TlZ5r9wPpPrl2djw3DPI9vHjZbJQMjYfDr5h15lSmjILv0DruUE3fYnXz3XdnzvHTK3SzgShePgz4TnVqkywJQkyZNeP/997n00kspLCwkIiKCr776iiuvNJsIN2zYQO/evTl6tJoTXrqZApBr3TN7Dd+sP8TDV7Xk3rCfSucQyz+xQUwHuG0h+Ae5r5IitZVhmF9SmftOE5QOQPYhsxW1TFAUnD/CbO3xtnG0jmwzW4XWfwKZe0+sD29s3mq+vfSPsPgLzL42tfX3c2Q7fDrmxCCMPe4yW88Lsk+Mu5SdUnGoyUmForxzP5bFx2xh9Asyg7TV17w0aj158TnL87Nt72v2a2p6qVN/TS4LQGPHjmXdunVMmTKFefPmMWvWLA4ePIi/v3kt+sMPP2Tq1KmsWrWqemfgZgpArvVe8m4mfPkHl7SM4v3bEiF1I3x2m9kHwxZuzi9WW/8TEvEEJcXml17WAfOLr3FPc/40b2a3m4M5rvvYnD6lIMtcb7HCJQ9B70dqf4tYcQEsetoc+LMq/ENKR92OLR1xu/Tnyc9DY81WJg+9A7Iy39+V6u32zDPPcMMNN9C7d29CQkKYNWuWI/wAvP322/Tt27dqtRavUTYx6uo9xyguseMb0w7u+MEcdK1RD4Ufkery8S3tD6T5pRysVki42FwGPg9bvjX7d3UeDo0vdHftzo2vDfo/a17GLBufCIt5F6FjOpEKQk3Z9CKVmbLDC1R5IMSQkBB8fMr3Rj969CghISHlQpEnUguQa9ntBuc/s5DM40V8ec9FdG4U4e4qiYh4lpIi81JoUJRn3bnnYpX5/q5SG1d4ePgp4QcgMjLS48OPuJ7VanHMDr9yl2f3FxMRcQsfP7OVR+GnyjzzIp94vMTSy2ArdqW7uSYiIuKNFIDELcr6Aa3cdRS7vYZuuRQRESmlACRu0T4+jCB/H7Lyi9mS6tnjRomIiOdRABK38PWx0rVJPUD9gEREpOYpAInbXNjMHGZeAUhERGqaApC4TQ9HR+ijVGE0BhERkSpTABK36dQwHH9fK0dyCth1xI0zb4uIiNdRABK3sfn6cH7pIIi6DCYiIjVJAUjcKrGpBkQUEZGapwAkbtWjqdkReoUCkIiI1CAFIHGrC5pE4Gu1cCDjOPuP5bm7OiIi4iUUgMStgvx96XBeOACrdqsVSEREaoYCkLid+gGJiEhNUwAStzt5PCAREZGaoAAkbtetSSQWC+w8nMvh7AJ3V0dERLyAApC4XXiQH21iwwD1AxIRkZqhACS1Qlk/oBU7091cExER8QYKQFIrlAWgOb/u47sNh9xcGxERqesUgKRW6NMuhstaNyC/yM7YD9fw2g/bNEGqiIi4jAKQ1Ap+PlbeHNmNWy9qCsAL32/l73PWkl9U4uaaiYhIXaQAJLWGr4+VCde249/Xd8DXamHe2oMMn7lcd4aJiIjTKQBJrTMisQnv3dqD8EA/ftubwXWv/cLGg1nurpaIiNQhCkBSK/VqEcW8ey6iWVQwBzPzuXHGMr7/I8Xd1RIRkTpCAUhqraZRwXxx90Vc3CKKvMIS7vpgNdMX71DnaBERqTYFIKnVwoP8eHdMd0b2bIJhwJT5m3l47noKitU5WkREqk4BSGo9Xx8r/7yuA/+8rj0+VgufrdnPiJkrSM9R52gREakaBSDxGCN7JvDumO6EBvjy655jXDdtKVtSst1dLRER8UAKQOJRLmnZgC/uvoiE+kHsP3acG15fyg+bU91dLRER8TAKQOJxWkSHMO+ei+jZrD65hSXcNutX3vx5pzpHi4jIOVMAEo8UEeTPe7f1YHiPRhgG/OubTTz62QYKi+3urpqIiHgAtwegadOmkZCQQEBAAImJiaxcufK02/7xxx8MGTKEhIQELBYLU6dOPWWbp556CovFUm5p06aNC89A3MXPx8qz13dkwjXtsFrMiVT/8tYKjuYWurtqIiJSy7k1AM2ZM4dx48YxceJE1qxZQ+fOnenXrx9paWkVbp+Xl0ezZs2YPHkysbGxpy23ffv2HDp0yLH88ssvrjoFcTOLxcKtFzflrdHdCbH5snLXUQZPW8q2VHWOFhGR03NrAHrppZe44447GDNmDO3atWPGjBkEBQXx9ttvV7h99+7def755xk2bBg2m+205fr6+hIbG+tYoqKiXHUKUktc3jqaz+/uRaPIQPYezeOG15exeEvFQVpERMRtAaiwsJDVq1fTp0+fE5WxWunTpw/JycnVKnvbtm3Ex8fTrFkzRowYwd69e8+4fUFBAVlZWeUW8TytYkL58p6L6ZEQSXZBMbe+u4p3lu5S52gRETmF2wLQkSNHKCkpISYmptz6mJgYUlKqPudTYmIi7777LvPnz2f69Ons2rWLSy65hOzs018SmTRpEuHh4Y6lUaNGVT6+uFdksD8f3J7ITV0bYjfg6a828vi83ykqUedoERE5we2doJ1twIAB3HTTTXTq1Il+/frx7bffkpGRwSeffHLafcaPH09mZqZj2bdvXw3WWJzN39fKczd24vGBbbFYYPaKvYx6eyUZeeocLSIiJrcFoKioKHx8fEhNLT+IXWpq6hk7OFdWREQErVq1Yvv27afdxmazERYWVm4Rz2axWLjj0ma8ObIbwf4+LNuRzuBpS9l5OMfdVRMRkVrAbQHI39+frl27kpSU5Fhnt9tJSkqiZ8+eTjtOTk4OO3bsIC4uzmlliue4sm0Mn93di/MiAtmdnseQ6ctYveeYu6slIiJu5tZLYOPGjWPmzJnMmjWLTZs2MXbsWHJzcxkzZgwAI0eOZPz48Y7tCwsLWbt2LWvXrqWwsJADBw6wdu3acq07Dz/8MEuWLGH37t0sW7aM66+/Hh8fH4YPH17j5ye1Q5vYML689yI6NwznWF4Rt8xczoI/qt7PTEREPJ+vOw8+dOhQDh8+zIQJE0hJSaFLly7Mnz/f0TF67969WK0nMtrBgwc5//zzHc9feOEFXnjhBXr37s3ixYsB2L9/P8OHDyc9PZ0GDRpw8cUXs3z5cho0aFCj5ya1S1SIjY/uvJD7Zv9G0uY0xn6wmqcGtWdkzwR3V01ERNzAYuge4VNkZWURHh5OZmam+gPVMcUldp788g8+WmkOjfC33s35R7/WWK0WN9dMRESqqzLf33XuLjCRM/H1sfLs9R14uG8rAGYs2cHfP1lLQXGJm2smIiI1SQFIvI7FYuHeK1rywk2d8bVa+HLtQUa/vYqs/CJ3V01ERGqIApB4rRu7NuTt0d0J9vcheWc6N89I5lDmcXdXS0REaoACkHi1S1s14JO/9aRBqI3NKdnc8PoytqRoIlURkbpOAUi8Xvv4cL64uxctokM4lJnPjTOWsWzHEXdXS0REXEgBSARoWC+IT//W05xINb+Y0W+v4su1B9xdLRERcREFIJFSEUH+vHdbDwZ2jKWwxM4DH6/ljSU7NJu8iEgdpAAkcpIAPx9eG34Bt17UFIBJ323m6a82UmJXCBIRqUsUgET+xGq1MOHadjxxdVsA3l22m7s/XE1+kcYKEhGpKxSARE7j9kua8dot5+PvY2XBH6mMeHMFx3IL3V0tERFxAgUgkTO4plM879/Wg7AAX1bvOcaQ6cvYdzTP3dUSEZFqUgASOYvEZvX5bGwvzosIZOeRXK5/fRkb9me6u1oiIlINCkAi56BlTCif392LtnFhHMkpYOh/k/lxS5q7qyUiIlWkACRyjmLCAvjkrgu5uEUUeYUl3D7rV+as2uvuaomISBUoAIlUQmiAH2+P7s4NF5xHid3gkc828J+FWzVWkIiIh1EAEqkkf18rL97UmXsvbwHAy0nbePSzDRSV2N1cMxEROVcKQCJVYLFYeLhfa/59fQesFpjz6z5un/WrZpMXEfEQCkAi1TAisQn//Ws3AvysLNl6mMueX8yU+ZvJPF7k7qqJiMgZKACJVFOfdjF8NrYXPRIiKSi2M33xDno//yNv/ryTgmKNHi0iUhtZDPXePEVWVhbh4eFkZmYSFhbm7uqIhzAMg0Wb0pgyfzPb03IAaFgvkIf7tmZQ53isVoubaygiUrdV5vtbAagCCkBSHcUldj5dvZ//LNpKalYBAO3jw3h0QBsuadnAzbUTEam7FICqSQFInOF4YQlvL93FjMU7yC4oBuCSllE80r8NHc4Ld3PtRETqHgWgalIAEmc6mlvIqz9s44PleygqMT9ug7vE81Df1jSKDHJz7URE6g4FoGpSABJX2Juexwvfb+F/6w4C4O9j5a89m3Dv5S2oF+zv5tqJiHg+BaBqUgASV9qwP5PJ8zexdHs6AKEBvoy9rDm3XtSUAD8fN9dORMRzKQBVkwKQuJphGPy07QiTv9vMpkNZAMSGBTDuqlYM6doQH90xJiJSaQpA1aQAJDXFbjeYt/YAL36/lQMZ5ijSrWJCeKR/G65oE43FoiAkInKuFICqSQFIalp+UQnvJ+/htR+3O0aR7tE0kvED2nB+43purp2IiGdQAKomBSBxl8y8Il5fsp13lu6msNicXHVgx1j+r18bmkYFu7l2IiK1mwJQNSkAibsdyDjOfxZu5bM1+zEM8LVa6JZQD6vFgt0wsBtmPyLDoNxz+5+en3i9/LZlz8v2sVhgzEUJ3Hlpc3efuohIlSkAVZMCkNQWm1OymPLdZn7cctjlx7JY4MPbE+nVPMrlxxIRcQUFoGpSAJLaZu2+DHYfycViAavFUrqApfSn1WLBajWfWzjNNtYTz0/exmKBt5fu4vM1B4gJs/HdA5cSqXGJRMQDKQBVkwKQeJu8wmKuefUXdh7OpU/bGGaO7Ko70ETE41Tm+9taQ3USkVosyN+XV4efj7+PlUWbUnl/+R53V0lExKUUgEQEgPbx4Tw6oA0A//pmE5tTstxcIxER11EAEhGHMRclcHnrBhQW27lv9m8cLyxxd5VERFxCAUhEHCwWC8/f1JkGoTa2peXwr282urtKIiIuoQAkIuVEhdh46ebOAHy4Yi/zf09xc41ERJxPAUhETnFJywbcdWkzAB75bD0HS+cpExGpKxSARKRCD/VtTaeG4WQeL+LBOWspsWvEDBGpOxSARKRC/r5WXhl2PsH+PqzcdZRpP253d5VERJxGAUhETishKphnBncA4OWkbfy6+6ibayQi4hxuD0DTpk0jISGBgIAAEhMTWbly5Wm3/eOPPxgyZAgJCQlYLBamTp1a7TJF5MxuuKAhg7vEU2I3eODjtWQeL3J3lUREqs2tAWjOnDmMGzeOiRMnsmbNGjp37ky/fv1IS0urcPu8vDyaNWvG5MmTiY2NdUqZInJ2zwzuQOPIIA5kHOexLzagGXRExNO5dS6wxMREunfvzmuvvQaA3W6nUaNG3HfffTz66KNn3DchIYEHH3yQBx980GllltFcYCKnWrsvgxunL6PYbvDckE7c3L2Ru6skIlKOR8wFVlhYyOrVq+nTp8+Jylit9OnTh+Tk5FpTpoiYujSK4KG+rQGY+L8/2J6W4+YaiYhUndsC0JEjRygpKSEmJqbc+piYGFJSqjbwWlXLLCgoICsrq9wiIqe669JmXNSiPseLSrj/o98oKNZUGSLimdzeCbo2mDRpEuHh4Y6lUSM17YtUxGq18NLNXYgM9mfjoSymfLfF3VUSEakStwWgqKgofHx8SE1NLbc+NTX1tB2cXVXm+PHjyczMdCz79u2r0vFFvEFMWADP39gJgLeX7uLHzbrBQEQ8j9sCkL+/P127diUpKcmxzm63k5SURM+ePWu0TJvNRlhYWLlFRE7vyrYxjO6VAMDDc9eRlpXv3gqJiFSSWy+BjRs3jpkzZzJr1iw2bdrE2LFjyc3NZcyYMQCMHDmS8ePHO7YvLCxk7dq1rF27lsLCQg4cOMDatWvZvn37OZcpIs7x6IA2tI0LIz23kIfmrsOuqTJExIP4uvPgQ4cO5fDhw0yYMIGUlBS6dOnC/PnzHZ2Y9+7di9V6IqMdPHiQ888/3/H8hRde4IUXXqB3794sXrz4nMoUEecI8PPh1eFduObVX/h52xHe/GUnd17a3N3VEhE5J24dB6i20jhAIufuo5V7Gf/5BnytFj6/uxedGka4u0oi4qU8YhwgEakbhnVvxIAOsRTbDe7/6DdyCordXSURkbNSABKRarFYLEy+oRPx4QHsTs9jwpe/u7tKIiJnpQAkItUWHuTHy8PPx2qBz9ccYN5vB9xdJRGRM1IAEhGn6J4Qyf1XtgTgiXm/szc9z801EhE5PQUgEXGaey9vQfeEeuQUFHPfx79RVGJ3+TGLS+zkFarfkYhUjltvgxeRusXXx8rUYeczYOpPrNuXwUsLt/JI/zZOKbuoxM6e9Fy2puawLTWHrWnZbE/NYeeRHIpKDOoH+9O4fhAJ9YNpHBlEk/rm0jgymKgQfywWi1PqISJ1g26Dr4Bugxepnu82HGLsh2uwWODD2xLp1SLqnPctKrGz+0gu29Jy2JqazbbUHLalZbPrSC5FJVX77yrY34fG9YNpUhqMGtcPoklkME3qBxEfEYiPVeFIpC6ozPe3AlAFFIBEqm/85xv4aOVeokNtzH/wUiKD/cu9Xlh8okVna2o220sDz64juRSfZlTpIH8fWkaH0DImlJbRIbSKCaVFdAhhgX7sO5rHnvQ89hzNZW966eP0XA5l5XOm/+X8fCw0rBd0UqvRiaDUKDKIAD8fZ/5aRMSFFICqSQFIpPqOF5Zw7Wu/sD0th8tbN2BI14aO1pxtqTlnDDrB/j60iAmlVXQILWNOBJ748ECslWytyS8qYf+x4+w9mlsaisxgtOdoHvuPHqfwLP2UYsMCOL9xBNd0iueKNtEE+isQidRWCkDVpAAk4hwbD2Yx+PWlFBZXHDJCbL60iA450ZoTY/6MDw+okT47JXaDlKx89qSbrUa70/McQWlveh7ZfxrUMcjfh6vaxXBtp3guaRWFzVdhSKQ2UQCqJgUgEeeZ++s+nl+whfiIQFrFnLhs1SomlLgaCjpVYRgGx/KK2Hk4h6TNaXy17iD7jx13vB4W4Ev/DrFc2zmens3q4+ujm2pF3E0BqJoUgETkzwzDYO2+DL5ad4iv1x8kLbvA8Vr9YH8Gdozj2s7xdGtSr9KX6UTEORSAqkkBSETOpMRusGr3Ub5ad5BvNxziWF6R47XYsACu6WSGoU4Nw2ttC5dIXaQAVE0KQCJyropK7Czbkc5X6w6y4PeUcv2GGkcGcW1nMwy1jglVGBJxMQWgalIAEpGqyC8q4aeth/lq/SEWbUzleFGJ47WW0SFc2zmeazrF0axBiBtrKVJ3KQBVkwKQiFRXXmExSZvMztOLtx4udydch/PCuLZTPFd3iqNhvaBKl20YBkUlBkUldgqL7RSV2Cko/VlYYqeo2KCwpITCYoOwQF/axYWp9Um8ggJQNSkAiYgzZeUXsfCPVL5af5Cftx2h5KTxj7o0iiAqxFYaXEoDTGmwKTwp4Jg/Dcf6yhiR2JhnruugztlS5ykAVZMCkIi4ytHcQub/nsJX6w6yfFf6GUepPldWC/j7WvHzsWIr/enva8XXamHnkVwMAwZ1jufFmzvjp9v1pQ5TAKomBSARqQmpWfn8tPUwJXbDEVr+HGL8fCz4+1rxP+l1x8/Sx2eay+x/6w4ybs5aiu0GV7SJZtotF2g0a6mzFICqSQFIROqSHzen8bcPVlNQbKdHQiRvju5GWICfu6sl4nSV+f5WW6iISB13eZto3r8tkVCbLyt3H2X4f5eTnlNw9h1F6jAFIBERL9CjaSQf3Xkh9YP9+eNgFje9kcyBjONn31GkjlIAEhHxEh3OC2fu33oSHx7AzsO53DR9GTsP57i7WiJuoQAkIuJFmjUI4dOxvWjWIJiDmfncNCOZ3w9kurtaIjVOAUhExMvERwTyyV09aR8fRnpuIcP/u5yVu466u1oiNUoBSETEC0WF2Pjozgvp0TSS7IJiRr69gh83p7m7WiI1RgFIRMRLhQX48d6tPbiiTTT5RXbueO9X/rfuoLurJVIjFIBERLxYgJ8Pb/y1K4M6x1NsN3jg49/4cMUed1dLxOUUgEREvJyfj5WpQ7vwlwsbYxjw+Be/8/ri7e6ulohLKQCJiAhWq4VnruvAPZc3B+C5+VuY9N0mNFmA1FUKQCIiAoDFYuH/+rXhsYFtAHhjyU4e+2JDudnrReoKBSARESnnzkubM/mGjlgt8NHKfdz/8W8UFtvdXS0Rp1IAEhGRUwzr0ZjXbrkAPx8L36w/xB3v/crxwhJ3V0vEaRSARESkQgM7xvHmqO4E+vmwZOth/vrWCjKPF7m7WiJOoQAkIiKn1btVAz64vQdhAb78uucYw/67nMPZmklePJ8CkIiInFHXJpHMuasnUSE2Nh3K4qYZy9h/LM/d1RKpFgUgERE5q7ZxYcz9W0/Oiwhkd3oeN05PZntatrurJVJlCkAiInJOmkYF89nYXrSIDiElK5+b31jO8p3pHMst1F1i4nEshka5OkVWVhbh4eFkZmYSFhbm7uqIiNQqR3MLGf3OStbvzyy33t/XSojNl2CbDyE2P0JsPgTbfAkpXYJLl1DHYx9CA3wJ9i9dH+Dr2N7ma8VisbjpDMVTVeb727eG6iQiInVEZLA/s++4kIc/WcfirWnkF5mtP4XFdo4WF3I0F+B4tY7hY7UQYvOlfog/sWEB5hJeupz0OCrYhtWqoCSVpxagCqgFSETk3BWX2MktKCGnsJjcgmKy882fuQXFZBdU9LjkxDaFxeTkF5NT9lolxxrytVqICQsgJsxGXHggMWEBxIbbiA0PJDYsgLjwAKLDbNh8fVx09jWjxG6wNTWbX/ccY/Xuo6zee4yiYoOWMSG0iQ2ldWwYbWJDaREdQoCfZ59rdVTm+1sBqAIKQCIi7mG3G+QWloWkIg7nFJCalc+hzHxSM0t/ZuWTkpVPWnYB5/oNVj/Yn5jSQBRzUitS8wbBtIgOJTzQz7UnVkl5hcWs3ZfB6t3H+HXPMdbsOUZ2QfFZ97NaICEq2AxFMWG0jg2lTWwojSODvKKlTAGomhSARERqv+ISO4dzCk4JR4cyzYCUUvrzXDpoR4faaBkTQstosxWlZXQILWNCiQz2r4EzgdSsfH7dfYxf9xxl9Z5j/HEw65Q52IL9fTi/cT26JdSjW5NIAv192JqazZaUbDanZLElJZtjeRUPVBno50OrmBBal7YWtY4JpXVsKA1CbTVxejXG4wLQtGnTeP7550lJSaFz5868+uqr9OjR47Tbz507lyeffJLdu3fTsmVLpkyZwsCBAx2vjx49mlmzZpXbp1+/fsyfP/+c6qMAJCJSNxiGwbG8IlJOCUfHOZiRz47DORzKzD/t/vWD/c1AVBqOWkaH0CImhAYhtip30rbbDbamZfPr7mOs3mOGnn1HT+0zFRceQLeESLo1qUfXJvVoExuKr8/pb942DIPD2QVsTikLRdlsSc1iW2oOBacJgfWD/UtDUajjUlqrmBCC/D2zi7BHBaA5c+YwcuRIZsyYQWJiIlOnTmXu3Lls2bKF6OjoU7ZftmwZl156KZMmTeKaa65h9uzZTJkyhTVr1tChQwfADECpqam88847jv1sNhv16tU7pzopAImIeI+s/CJ2pOWwLS2H7Wk5bEvNZltaDvuPnb4jd3ign6OlqEVpa1HL6BDiwgNOCUbHC0vMy1l7jrJq9zHW7D1Gdn75y1lWC7SJDaNbghl2uiVEcl5EoFPOr8RusDs990QoKm0t2nM0r8JLiBYLNI4MomuTevRu1YBLWjaosZaw6vKoAJSYmEj37t157bXXALDb7TRq1Ij77ruPRx999JTthw4dSm5uLl9//bVj3YUXXkiXLl2YMWMGYAagjIwM5s2bV6U6KQCJiEheYTE70nLZlpZtBqPSgLQnPRf7ab45Q2y+NC8NRiE2X37ba17OKv7TDkH+PpzfOIKuTcwWnvMbRxAaULP9kPIKi9meluNoMSoLSEdyyk91YrFAp4YRXNaqAb1bN6Bzwwh8aml/Io+5Db6wsJDVq1czfvx4xzqr1UqfPn1ITk6ucJ/k5GTGjRtXbl2/fv1OCTuLFy8mOjqaevXqccUVV/Cvf/2L+vXrV1hmQUEBBQUn3vCsrKwqnpGIiNQVQf6+dGwYTseG4eXW5xeVsOtIrhmISluLtqXlsPtILjkFxazbl8G6fRnl9okJszkuZ3VrEknbuDNfzqoJQf6+dGoYQaeGEeXWp+cUsPFQFr9sP8KSLYfZnJLtOKeXk7YRHujHJS2j6N2qAb1bNSA6LMA9J1BNbg1AR44coaSkhJiYmHLrY2Ji2Lx5c4X7pKSkVLh9SkqK43n//v254YYbaNq0KTt27OCxxx5jwIABJCcn4+Nz6u2BkyZN4umnn3bCGYmISF0X4OdD27gw2saVb2EoLLazJ90MRttSc8g8XkSnhuF0bVKPhvUCPWZgx/ohNi5paV76Gj+gLSmZ+fy07TBLth7m562HyTxexNfrD/H1+kOAOU1KWRjq2qQe/r6eMcmEZ/ZyOothw4Y5Hnfs2JFOnTrRvHlzFi9ezJVXXnnK9uPHjy/XqpSVlUWjRo1qpK4iIlI3+Ptazb5AMaHQ0d21cZ7Y8ABu7taIm7s1orjEzrr9mSzZagai9fsz2HQoi02HspixZAfB/j70anGidahRZJC7q39abg1AUVFR+Pj4kJqaWm59amoqsbGxFe4TGxtbqe0BmjVrRlRUFNu3b68wANlsNmy2unUroIiIiLP5+ljpWnpX2rirWpGeU+C4VPbTtsMcySlk4cZUFm40v6ebNQh2hKELm9WvVYM0ujUA+fv707VrV5KSkhg8eDBgdoJOSkri3nvvrXCfnj17kpSUxIMPPuhYt3DhQnr27Hna4+zfv5/09HTi4uKcWX0RERGvVj/ExnVdzuO6LudhtxtsPJRltg5tOczqvcfYeTiXnYdzeWfpbmy+VhKb1XcEouYNgt16WdDtd4HNmTOHUaNG8cYbb9CjRw+mTp3KJ598wubNm4mJiWHkyJGcd955TJo0CTBvg+/duzeTJ0/m6quv5uOPP+bZZ5913Aafk5PD008/zZAhQ4iNjWXHjh384x//IDs7mw0bNpxTS4/uAhMREamerPwilm0/4ghEB/803tKw7o2YPKSTc4/pKXeBgXlb++HDh5kwYQIpKSl06dKF+fPnOzo67927F6v1RIeqXr16MXv2bJ544gkee+wxWrZsybx58xxjAPn4+LB+/XpmzZpFRkYG8fHx9O3bl2eeeUaXuURERGpIWIAf/TvE0b9DHIZhsD0tx9F3aMXOo6fcfVbT3N4CVBupBUhERMR18grNgSCdPeK0R7UAiYiIiHepDVNteMbN+iIiIiJOpAAkIiIiXkcBSERERLyOApCIiIh4HQUgERER8ToKQCIiIuJ1FIBERETE6ygAiYiIiNdRABIRERGvowAkIiIiXkcBSERERLyOApCIiIh4HQUgERER8Trun461FjIMA4CsrCw310RERETOVdn3dtn3+JkoAFUgOzsbgEaNGrm5JiIiIlJZ2dnZhIeHn3Ebi3EuMcnL2O12Dh48SGhoKBaLxallZ2Vl0ahRI/bt20dYWJhTy65tdK51lzedr8617vKm8/WWczUMg+zsbOLj47Faz9zLRy1AFbBarTRs2NClxwgLC6vT/whPpnOtu7zpfHWudZc3na83nOvZWn7KqBO0iIiIeB0FIBEREfE6CkA1zGazMXHiRGw2m7ur4nI617rLm85X51p3edP5etO5nit1ghYRERGvoxYgERER8ToKQCIiIuJ1FIBERETE6ygAiYiIiNdRAHKBadOmkZCQQEBAAImJiaxcufKM28+dO5c2bdoQEBBAx44d+fbbb2uoplU3adIkunfvTmhoKNHR0QwePJgtW7accZ93330Xi8VSbgkICKihGlfdU089dUq927Rpc8Z9PPE9LZOQkHDK+VosFu65554Kt/ek9/Wnn37i2muvJT4+HovFwrx588q9bhgGEyZMIC4ujsDAQPr06cO2bdvOWm5lP/M14UznWlRUxCOPPELHjh0JDg4mPj6ekSNHcvDgwTOWWZXPQk0523s7evToU+rev3//s5brae8tUOHn12Kx8Pzzz5+2zNr83rqKApCTzZkzh3HjxjFx4kTWrFlD586d6devH2lpaRVuv2zZMoYPH85tt93Gb7/9xuDBgxk8eDC///57Dde8cpYsWcI999zD8uXLWbhwIUVFRfTt25fc3Nwz7hcWFsahQ4ccy549e2qoxtXTvn37cvX+5ZdfTrutp76nZVatWlXuXBcuXAjATTfddNp9POV9zc3NpXPnzkybNq3C15977jleeeUVZsyYwYoVKwgODqZfv37k5+eftszKfuZrypnONS8vjzVr1vDkk0+yZs0aPv/8c7Zs2cKgQYPOWm5lPgs16WzvLUD//v3L1f2jjz46Y5me+N4C5c7x0KFDvP3221gsFoYMGXLGcmvre+syhjhVjx49jHvuucfxvKSkxIiPjzcmTZpU4fY333yzcfXVV5dbl5iYaNx1110uraezpaWlGYCxZMmS027zzjvvGOHh4TVXKSeZOHGi0blz53Pevq68p2UeeOABo3nz5obdbq/wdU99XwHjiy++cDy32+1GbGys8fzzzzvWZWRkGDabzfjoo49OW05lP/Pu8OdzrcjKlSsNwNizZ89pt6nsZ8FdKjrfUaNGGdddd12lyqkr7+11111nXHHFFWfcxlPeW2dSC5ATFRYWsnr1avr06eNYZ7Va6dOnD8nJyRXuk5ycXG57gH79+p12+9oqMzMTgMjIyDNul5OTQ5MmTWjUqBHXXXcdf/zxR01Ur9q2bdtGfHw8zZo1Y8SIEezdu/e029aV9xTMf9MffPABt9566xknBvbU9/Vku3btIiUlpdx7Fx4eTmJi4mnfu6p85murzMxMLBYLERERZ9yuMp+F2mbx4sVER0fTunVrxo4dS3p6+mm3rSvvbWpqKt988w233XbbWbf15Pe2KhSAnOjIkSOUlJQQExNTbn1MTAwpKSkV7pOSklKp7Wsju93Ogw8+yEUXXUSHDh1Ou13r1q15++23+fLLL/nggw+w2+306tWL/fv312BtKy8xMZF3332X+fPnM336dHbt2sUll1xCdnZ2hdvXhfe0zLx588jIyGD06NGn3cZT39c/K3t/KvPeVeUzXxvl5+fzyCOPMHz48DNOlFnZz0Jt0r9/f9577z2SkpKYMmUKS5YsYcCAAZSUlFS4fV15b2fNmkVoaCg33HDDGbfz5Pe2qjQbvFTbPffcw++//37W68U9e/akZ8+ejue9evWibdu2vPHGGzzzzDOurmaVDRgwwPG4U6dOJCYm0qRJEz755JNz+qvKk7311lsMGDCA+Pj4027jqe+rmIqKirj55psxDIPp06efcVtP/iwMGzbM8bhjx4506tSJ5s2bs3jxYq688ko31sy13n77bUaMGHHWGxM8+b2tKrUAOVFUVBQ+Pj6kpqaWW5+amkpsbGyF+8TGxlZq+9rm3nvv5euvv+bHH3+kYcOGldrXz8+P888/n+3bt7uodq4RERFBq1atTltvT39Py+zZs4dFixZx++23V2o/T31fy96fyrx3VfnM1yZl4WfPnj0sXLjwjK0/FTnbZ6E2a9asGVFRUaetu6e/twA///wzW7ZsqfRnGDz7vT1XCkBO5O/vT9euXUlKSnKss9vtJCUllfsL+WQ9e/Ystz3AwoULT7t9bWEYBvfeey9ffPEFP/zwA02bNq10GSUlJWzYsIG4uDgX1NB1cnJy2LFjx2nr7anv6Z+98847REdHc/XVV1dqP099X5s2bUpsbGy59y4rK4sVK1ac9r2ryme+tigLP9u2bWPRokXUr1+/0mWc7bNQm+3fv5/09PTT1t2T39syb731Fl27dqVz586V3teT39tz5u5e2HXNxx9/bNhsNuPdd981Nm7caNx5551GRESEkZKSYhiGYfz1r381Hn30Ucf2S5cuNXx9fY0XXnjB2LRpkzFx4kTDz8/P2LBhg7tO4ZyMHTvWCA8PNxYvXmwcOnTIseTl5Tm2+fO5Pv3008aCBQuMHTt2GKtXrzaGDRtmBAQEGH/88Yc7TuGcPfTQQ8bixYuNXbt2GUuXLjX69OljREVFGWlpaYZh1J339GQlJSVG48aNjUceeeSU1zz5fc3OzjZ+++0347fffjMA46WXXjJ+++03x51PkydPNiIiIowvv/zSWL9+vXHdddcZTZs2NY4fP+4o44orrjBeffVVx/Ozfebd5UznWlhYaAwaNMho2LChsXbt2nKf4YKCAkcZfz7Xs30W3OlM55udnW08/PDDRnJysrFr1y5j0aJFxgUXXGC0bNnSyM/Pd5RRF97bMpmZmUZQUJAxffr0CsvwpPfWVRSAXODVV181GjdubPj7+xs9evQwli9f7nitd+/exqhRo8pt/8knnxitWrUy/P39jfbt2xvffPNNDde48oAKl3feecexzZ/P9cEHH3T8XmJiYoyBAwcaa9asqfnKV9LQoUONuLg4w9/f3zjvvPOMoUOHGtu3b3e8Xlfe05MtWLDAAIwtW7ac8ponv68//vhjhf9uy87HbrcbTz75pBETE2PYbDbjyiuvPOV30KRJE2PixInl1p3pM+8uZzrXXbt2nfYz/OOPPzrK+PO5nu2z4E5nOt+8vDyjb9++RoMGDQw/Pz+jSZMmxh133HFKkKkL722ZN954wwgMDDQyMjIqLMOT3ltXsRiGYbi0iUlERESkllEfIBEREfE6CkAiIiLidRSARERExOsoAImIiIjXUQASERERr6MAJCIiIl5HAUhERES8jgKQiMg5sFgszJs3z93VEBEnUQASkVpv9OjRWCyWU5b+/fu7u2oi4qF83V0BEZFz0b9/f955551y62w2m5tqIyKeTi1AIuIRbDYbsbGx5ZZ69eoB5uWp6dOnM2DAAAIDA2nWrBmffvppuf03bNjAFVdcQWBgIPXr1+fOO+8kJyen3DZvv/027du3x2azERcXx7333lvu9SNHjnD99dcTFBREy5Yt+d///ufakxYRl1EAEpE64cknn2TIkCGsW7eOESNGMGzYMDZt2gRAbm4u/fr1o169eqxatYq5c+eyaNGicgFn+vTp3HPPPdx5551s2LCB//3vf7Ro0aLcMZ5++mluvvlm1q9fz8CBAxkxYgRHjx6t0fMUESdx92ysIiJnM2rUKMPHx8cIDg4ut/z73/82DMMwAONvf/tbuX0SExONsWPHGoZhGP/973+NevXqGTk5OY7Xv/nmG8NqtTpmBI+Pjzcef/zx09YBMJ544gnH85ycHAMwvvvuO6edp4jUHPUBEhGPcPnllzN9+vRy6yIjIx2Pe/bsWe61nj17snbtWgA2bdpE586dCQ4Odrx+0UUXYbfb2bJlCxaLhYMHD3LllVeesQ6dOnVyPA4ODiYsLIy0tLSqnpKIuJECkIh4hODg4FMuSTlLYGDgOW3n5+dX7rnFYsFut7uiSiLiYuoDJCJ1wvLly0953rZtWwDatm3LunXryM3Ndby+dOlSrFYrrVu3JjQ0lISEBJKSkmq0ziLiPmoBEhGPUFBQQEpKSrl1vr6+REVFATB37ly6devGxRdfzIcffsjKlSt56623ABgxYgQTJ05k1KhRPPXUUxw+fJj77ruPv/71r8TExADw1FNP8be//Y3o6GgGDBhAdnY2S5cu5b777qvZExWRGqEAJCIeYf78+cTFxZVb17p1azZv3gyYd2h9/PHH3H333cTFxfHRRx/Rrl07AIKCgliwYAEPPPAA3bt3JygoiCFDhvDSSy85yho1ahT5+fn85z//4eGHHyYqKoobb7yx5k5QRGqUxTAMw92VEBGpDovFwhdffMHgwYPdXRUR8RDqAyQiIiJeRwFIREREvI76AImIx9OVfBGpLLUAiYiIiNdRABIRERGvowAkIiIiXkcBSERERLyOApCIiIh4HQUgERER8ToKQCIiIuJ1FIBERETE6ygAiYiIiNf5f9gkSIBY1qVqAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_true = p_valid['targets']\n",
        "val_pred = []\n",
        "for p in preds:\n",
        "    val_pred+=[round(p,0)]\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(val_true,val_pred,target_names=class_names,digits=4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n0NBZUPXIgYV",
        "outputId": "bb4ecde1-72bc-4ac0-e2b8-185d0aeab90b"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham     0.9586    1.0000    0.9789       139\n",
            "        spam     1.0000    0.7143    0.8333        21\n",
            "\n",
            "    accuracy                         0.9625       160\n",
            "   macro avg     0.9793    0.8571    0.9061       160\n",
            "weighted avg     0.9641    0.9625    0.9598       160\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bestscores = []\n",
        "bestscores.append(bestscore)\n",
        "\n",
        "for fold in range(1,5):\n",
        "\n",
        "    # initializing the data\n",
        "    p_train = train[train[\"kfold\"]!=fold].reset_index(drop=True)\n",
        "    p_valid = train[train[\"kfold\"]==fold].reset_index(drop=True)\n",
        "\n",
        "    train_dataset = BERTDataSet(p_train[\"text\"],p_train['targets'])\n",
        "    valid_dataset = BERTDataSet(p_valid[\"text\"],p_valid['targets'])\n",
        "\n",
        "    train_dataloader = DataLoader(train_dataset,batch_size=train_batch,shuffle = True,num_workers=4,pin_memory=True)\n",
        "    valid_dataloader = DataLoader(valid_dataset,batch_size=valid_batch,shuffle = False,num_workers=4,pin_memory=True)\n",
        "\n",
        "    model = transformers.RobertaForSequenceClassification.from_pretrained(\"roberta-base\", num_labels=1)\n",
        "\n",
        "    model.to(device)\n",
        "    LR=2e-5\n",
        "    optimizer = AdamW(model.parameters(), LR,betas=(0.9, 0.999), weight_decay=1e-2) # AdamW optimizer\n",
        "    train_steps = int(len(p_train)/train_batch*epochs)\n",
        "    num_steps = int(train_steps*0.1)\n",
        "    scheduler = get_linear_schedule_with_warmup(optimizer, num_steps, train_steps)\n",
        "\n",
        "    trainlosses = []\n",
        "    vallosses = []\n",
        "    bestscore = None\n",
        "    trainscores = []\n",
        "    validscores = []\n",
        "\n",
        "    for epoch in tqdm(range(epochs)):\n",
        "\n",
        "        print(\"---------------\" + str(epoch) + \"start-------------\")\n",
        "\n",
        "        trainloss,trainscore = training(train_dataloader,model,optimizer,scheduler)\n",
        "        trainlosses.append(trainloss)\n",
        "        trainscores.append(trainscore)\n",
        "\n",
        "        print(\"trainscore is \" + str(trainscore))\n",
        "\n",
        "        preds,validloss,valscore=validating(valid_dataloader,model)\n",
        "        vallosses.append(validloss)\n",
        "        validscores.append(valscore)\n",
        "\n",
        "        print(\"valscore is \" + str(valscore))\n",
        "\n",
        "        if bestscore is None:\n",
        "            bestscore = valscore\n",
        "\n",
        "            print(\"Save first model\")\n",
        "\n",
        "            state = {\n",
        "                            'state_dict': model.state_dict(),\n",
        "                            'optimizer_dict': optimizer.state_dict(),\n",
        "                            \"bestscore\":bestscore\n",
        "                        }\n",
        "\n",
        "            torch.save(state, \"model\" + str(fold) + \".pth\")\n",
        "\n",
        "        elif bestscore > valscore:\n",
        "            bestscore = valscore\n",
        "            print(\"found better point\")\n",
        "\n",
        "            state = {\n",
        "                            'state_dict': model.state_dict(),\n",
        "                            'optimizer_dict': optimizer.state_dict(),\n",
        "                            \"bestscore\":bestscore\n",
        "                        }\n",
        "            torch.save(state, \"model\"+ str(fold) + \".pth\")\n",
        "\n",
        "        else:\n",
        "            pass\n",
        "\n",
        "\n",
        "    bestscores.append(bestscore)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dVzUXeyGJvQ_",
        "outputId": "6a721879-6764-4c86-cfca-778e5444b8d1"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------0start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.36322066\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 0.3419048\n",
            "Save first model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  5%|▌         | 1/20 [01:15<23:56, 75.63s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------1start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.34109956\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 0.2826285\n",
            "found better point\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|█         | 2/20 [02:26<21:53, 72.99s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------2start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.28787962\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 0.27268434\n",
            "found better point\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 15%|█▌        | 3/20 [03:43<21:07, 74.59s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------3start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.21122476\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 0.19515899\n",
            "found better point\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 4/20 [04:53<19:23, 72.74s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------4start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.18200316\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            " 25%|██▌       | 5/20 [06:01<17:45, 71.06s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 0.19775231\n",
            "---------------5start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.14943168\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            " 30%|███       | 6/20 [07:03<15:54, 68.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 0.20007752\n",
            "---------------6start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.12389011\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 0.17362006\n",
            "found better point\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 35%|███▌      | 7/20 [08:22<15:29, 71.47s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------7start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.11022654\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            " 40%|████      | 8/20 [09:24<13:44, 68.67s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 0.19102383\n",
            "---------------8start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.10315183\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            " 45%|████▌     | 9/20 [10:26<12:11, 66.53s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 0.20544265\n",
            "---------------9start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.09841762\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            " 50%|█████     | 10/20 [11:28<10:52, 65.24s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 0.18211147\n",
            "---------------10start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.09268854\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            " 55%|█████▌    | 11/20 [12:30<09:37, 64.14s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 0.20934302\n",
            "---------------11start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.08384717\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            " 60%|██████    | 12/20 [13:33<08:29, 63.73s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 0.18751615\n",
            "---------------12start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.089973554\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 0.16816585\n",
            "found better point\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 65%|██████▌   | 13/20 [14:43<07:39, 65.64s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------13start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.085390665\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 0.15985608\n",
            "found better point\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|███████   | 14/20 [15:54<06:43, 67.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------14start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.084817775\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            " 75%|███████▌  | 15/20 [16:57<05:29, 65.95s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 0.16971442\n",
            "---------------15start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.082421586\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            " 80%|████████  | 16/20 [17:59<04:19, 64.91s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 0.16708882\n",
            "---------------16start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.08224672\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            " 85%|████████▌ | 17/20 [19:02<03:12, 64.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 0.16675583\n",
            "---------------17start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.08108589\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            " 90%|█████████ | 18/20 [20:04<02:07, 63.76s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 0.16498075\n",
            "---------------18start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.08294387\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            " 95%|█████████▌| 19/20 [21:07<01:03, 63.40s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 0.16558127\n",
            "---------------19start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.07861174\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "100%|██████████| 20/20 [22:10<00:00, 66.53s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 0.16733325\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------0start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.3667897\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 0.33675075\n",
            "Save first model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  5%|▌         | 1/20 [01:11<22:40, 71.58s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------1start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.2987321\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 0.28568327\n",
            "found better point\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|█         | 2/20 [02:17<20:27, 68.20s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------2start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.23009159\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 0.2386933\n",
            "found better point\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 15%|█▌        | 3/20 [03:23<19:05, 67.40s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------3start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.18214302\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            " 20%|██        | 4/20 [04:24<17:14, 64.68s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 0.24492523\n",
            "---------------4start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.1557908\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 0.2323102\n",
            "found better point\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 25%|██▌       | 5/20 [05:39<17:06, 68.44s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------5start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.13293359\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            " 30%|███       | 6/20 [06:39<15:20, 65.74s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 0.26352185\n",
            "---------------6start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.13256165\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            " 35%|███▌      | 7/20 [07:39<13:48, 63.70s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 0.24050799\n",
            "---------------7start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.12373372\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            " 40%|████      | 8/20 [08:39<12:31, 62.59s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 0.25558507\n",
            "---------------8start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.10799825\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            " 45%|████▌     | 9/20 [09:40<11:21, 61.92s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 0.24797377\n",
            "---------------9start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.10663269\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            " 50%|█████     | 10/20 [10:40<10:12, 61.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 0.26721162\n",
            "---------------10start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.10200192\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            " 55%|█████▌    | 11/20 [11:40<09:08, 60.94s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 0.25668284\n",
            "---------------11start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.09931833\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            " 60%|██████    | 12/20 [12:39<08:04, 60.59s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 0.25090423\n",
            "---------------12start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.09107683\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            " 65%|██████▌   | 13/20 [13:39<07:02, 60.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 0.2730329\n",
            "---------------13start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.08695833\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            " 70%|███████   | 14/20 [14:41<06:04, 60.82s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 0.2716788\n",
            "---------------14start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.087062806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            " 75%|███████▌  | 15/20 [15:48<05:13, 62.62s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 0.27533248\n",
            "---------------15start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.08179469\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            " 80%|████████  | 16/20 [16:49<04:08, 62.08s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 0.27624226\n",
            "---------------16start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.072466515\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            " 85%|████████▌ | 17/20 [17:49<03:04, 61.54s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 0.2674886\n",
            "---------------17start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.06624618\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            " 90%|█████████ | 18/20 [18:50<02:02, 61.26s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 0.26947135\n",
            "---------------18start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.06275175\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            " 95%|█████████▌| 19/20 [19:51<01:01, 61.24s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 0.26792577\n",
            "---------------19start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.0604865\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "100%|██████████| 20/20 [20:54<00:00, 62.73s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 0.2727439\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------0start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.39650968\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 0.34671617\n",
            "Save first model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  5%|▌         | 1/20 [01:12<22:50, 72.13s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------1start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.32979795\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 0.23345716\n",
            "found better point\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|█         | 2/20 [02:42<24:47, 82.65s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------2start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.2542014\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            " 15%|█▌        | 3/20 [03:43<20:43, 73.15s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 0.25698245\n",
            "---------------3start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.20039792\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 0.22588497\n",
            "found better point\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 4/20 [05:00<19:53, 74.62s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------4start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.16243277\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 0.20696919\n",
            "found better point\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 25%|██▌       | 5/20 [06:11<18:17, 73.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------5start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.13091557\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 0.20611419\n",
            "found better point\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|███       | 6/20 [07:20<16:46, 71.92s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------6start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.11306056\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 0.19738042\n",
            "found better point\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 35%|███▌      | 7/20 [08:28<15:15, 70.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------7start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.08862571\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            " 40%|████      | 8/20 [09:28<13:27, 67.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 0.20246752\n",
            "---------------8start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.078335136\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            " 45%|████▌     | 9/20 [10:29<11:56, 65.13s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 0.20364624\n",
            "---------------9start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.07817603\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 0.19255474\n",
            "found better point\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 10/20 [11:35<10:56, 65.61s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------10start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.07237845\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 0.19178009\n",
            "found better point\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 55%|█████▌    | 11/20 [12:43<09:56, 66.23s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------11start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.07775838\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 0.18890812\n",
            "found better point\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 12/20 [13:57<09:09, 68.68s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------12start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.07246124\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            " 65%|██████▌   | 13/20 [14:59<07:44, 66.40s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 0.2057266\n",
            "---------------13start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.07440602\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            " 70%|███████   | 14/20 [16:05<06:38, 66.35s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 0.19275562\n",
            "---------------14start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.05885129\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            " 75%|███████▌  | 15/20 [17:07<05:24, 64.96s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 0.20068988\n",
            "---------------15start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.0569361\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            " 80%|████████  | 16/20 [18:07<04:14, 63.73s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 0.19261163\n",
            "---------------16start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.064056866\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            " 85%|████████▌ | 17/20 [19:08<03:08, 62.76s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 0.1901906\n",
            "---------------17start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.056247618\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            " 90%|█████████ | 18/20 [20:09<02:04, 62.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 0.18998496\n",
            "---------------18start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.050960604\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            " 95%|█████████▌| 19/20 [21:09<01:01, 61.61s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 0.18973272\n",
            "---------------19start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.05142934\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "100%|██████████| 20/20 [22:10<00:00, 66.52s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 0.1903385\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------0start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.37619933\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 0.34724864\n",
            "Save first model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  5%|▌         | 1/20 [01:11<22:45, 71.88s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------1start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.30835843\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 0.255557\n",
            "found better point\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|█         | 2/20 [02:18<20:41, 68.95s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------2start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.22734411\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            " 15%|█▌        | 3/20 [03:19<18:29, 65.24s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 0.2716957\n",
            "---------------3start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.18498307\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 0.20798141\n",
            "found better point\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 4/20 [04:27<17:38, 66.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------4start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.15707196\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 0.20253493\n",
            "found better point\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 25%|██▌       | 5/20 [05:39<17:06, 68.44s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------5start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.1780087\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 0.1906316\n",
            "found better point\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|███       | 6/20 [06:48<16:01, 68.70s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------6start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.142703\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            " 35%|███▌      | 7/20 [07:49<14:16, 65.91s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 0.21048585\n",
            "---------------7start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.11316141\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            " 40%|████      | 8/20 [08:48<12:47, 63.98s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 0.21456999\n",
            "---------------8start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.114930525\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            " 45%|████▌     | 9/20 [09:50<11:34, 63.12s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 0.2198583\n",
            "---------------9start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.10354\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            " 50%|█████     | 10/20 [10:50<10:21, 62.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 0.20315354\n",
            "---------------10start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.08405537\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            " 55%|█████▌    | 11/20 [11:50<09:13, 61.54s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 0.21401507\n",
            "---------------11start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.094777495\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            " 60%|██████    | 12/20 [12:51<08:10, 61.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 0.20583779\n",
            "---------------12start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.08729616\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            " 65%|██████▌   | 13/20 [13:52<07:09, 61.39s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 0.20243777\n",
            "---------------13start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.088767454\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            " 70%|███████   | 14/20 [14:52<06:05, 60.93s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 0.20343016\n",
            "---------------14start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.0819312\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            " 75%|███████▌  | 15/20 [15:58<05:12, 62.57s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 0.203405\n",
            "---------------15start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.078883916\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            " 80%|████████  | 16/20 [17:00<04:09, 62.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 0.2029247\n",
            "---------------16start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.073298946\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            " 85%|████████▌ | 17/20 [18:02<03:06, 62.01s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 0.1991165\n",
            "---------------17start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.075299844\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            " 90%|█████████ | 18/20 [19:02<02:03, 61.63s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 0.19810475\n",
            "---------------18start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.073500566\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            " 95%|█████████▌| 19/20 [20:03<01:01, 61.34s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 0.19682468\n",
            "---------------19start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.075378716\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "100%|██████████| 20/20 [21:03<00:00, 63.20s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 0.19700488\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bestscores"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wfa-1-tnLfq7",
        "outputId": "b6952c53-e6f2-4a0b-b87f-96e9e3ac7b25"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.18486586, 0.15985608, 0.2323102, 0.18890812, 0.1906316]"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.mean(bestscores)\n",
        "print(\"cv = \" + str(np.mean(bestscores)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NpmeTFaLgcJF",
        "outputId": "81c46ef5-3725-4707-d244-17f3535c6a2b"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cv = 0.19131437\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predicting(test_dataloader,model):\n",
        "\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    allpreds = []\n",
        "    preds = []\n",
        "    allvalloss=0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for a in test_dataloader:\n",
        "\n",
        "            ids = a[\"ids\"].to(device)\n",
        "            mask = a[\"mask\"].to(device)\n",
        "\n",
        "            output = model(ids,mask)\n",
        "            output = output[\"logits\"].squeeze(-1)\n",
        "            preds.append(output.cpu().numpy())\n",
        "\n",
        "        preds = np.concatenate(preds)\n",
        "        allpreds.append(preds)\n",
        "\n",
        "    return allpreds"
      ],
      "metadata": {
        "id": "p3rgtWaEgeJv"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tpreds = predicting(test_dataloader,model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PifUowXMghBp",
        "outputId": "0ab23724-25f9-4569-c047-32eb3a5a0354"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_true = p_test['targets']\n",
        "test_pred = []\n",
        "for p in tpreds[0]:\n",
        "    test_pred+=[round(p,0)]\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(test_true,test_pred,target_names=class_names,digits=4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E1MbemI6gls7",
        "outputId": "36a3987f-49ca-4986-e5d4-f63d873595fa"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham     0.9607    0.9884    0.9744       173\n",
            "        spam     0.9091    0.7407    0.8163        27\n",
            "\n",
            "    accuracy                         0.9550       200\n",
            "   macro avg     0.9349    0.8646    0.8953       200\n",
            "weighted avg     0.9537    0.9550    0.9530       200\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HH5zXpHtgqBx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}